---
title: "When Do Surveys Produce False Positives for Regime Support? A Sensitivity Gradient Approach to Measurement Distortion in Autocratizing Regimes"
author:
  - name: Jeffrey Stark
    affiliations:
      - name: Yonsei University
        department: Department of Sociology
    email: jeffrey.stark@yonsei.ac.kr
    corresponding: true
date: today
abstract: |
  Scholars of democratic backsliding rely on survey data to track regime legitimacy, yet the same repressive forces that dismantle institutions also distort the instruments used to measure public attitudes. This article develops a "sensitivity gradient" framework to identify measurement distortion—the aggregate effect of preference falsification and compositional selection—during authoritarian consolidation. I argue that under repression, survey reliability degrades along a predictable gradient: high-sensitivity items (e.g., trust in police) inflate due to strategic compliance and the exit of critics, while low-sensitivity items (e.g., abstract democratic values) remain comparatively robust. Testing this framework using a natural quasi-experiment in Hong Kong (the 2020 National Security Law), I find a stark "trust paradox": trust in police surged ($d \approx +0.49$) while perceived democratic suitability collapsed ($d = -0.54$). Furthermore, the canonical "critical citizens" correlation reverses, a diagnostic signal that standard survey relationships have broken down. These findings challenge "authoritarian resilience" interpretations of rising trust, suggesting instead that autocratization generates systematic false positives for regime support.
keywords:
  - survey measurement
  - autocratization 
  - preference falsification 
  - democratic backsliding 
  - Hong Kong 
  - comparative methodology
format:
  pdf:
    documentclass: article
    classoption: [12pt, letterpaper]
    geometry:
      - margin=1in
    linestretch: 2
    number-sections: true
    colorlinks: true
    keep-tex: true
    include-in-header:
      - text: |
          \usepackage{setspace}
          \usepackage{booktabs}
          \usepackage{longtable}
          \usepackage{array}
          \usepackage{multirow}
          \usepackage{float}
          \usepackage{graphicx}
          \usepackage{threeparttable}
          \usepackage{threeparttablex}
          \floatplacement{figure}{H}
          \floatplacement{table}{H}
          \raggedright
  html:
    toc: true
    toc-depth: 3
    number-sections: true
    theme: cosmo
bibliography: references.bib
csl: chicago-author-date.csl
execute:
  echo: false
  warning: false
  message: false
---

```{r setup}
#| include: false
library(tidyverse)
library(knitr)
library(kableExtra)

knitr::opts_chunk$set(
  echo = FALSE, message = FALSE, warning = FALSE,
  fig.align = "center", fig.pos = "H", out.width = "100%"
)

# Load results from the HK analysis pipeline
results_path <- "../../hong-kong-democratic-erosion/analysis/results"

load(file.path(results_path, "prepared_data.RData"))
load(file.path(results_path, "descriptive_results.RData"))

if (file.exists(file.path(results_path, "main_analysis_results.RData"))) {
  load(file.path(results_path, "main_analysis_results.RData"))
}

if (file.exists(file.path(results_path, "robustness_results.RData"))) {
  load(file.path(results_path, "robustness_results.RData"))
}

if (file.exists(file.path(results_path, "alt_explanations_results.RData"))) {
  load(file.path(results_path, "alt_explanations_results.RData"))
}
```

# Introduction

Scholars of democratic erosion face a fundamental identification challenge: the same coercive forces that dismantle democratic institutions also reshape the conditions under which citizens evaluate them. As regimes consolidate control, cross-national surveys often record puzzling spikes in institutional trust and regime satisfaction. Do these shifts reflect genuine "authoritarian resilience" [@Nathan2003-rz] driven by performance legitimacy and a craving for order? Or do they reflect measurement distortion—a mirage created when critics either hide their true preferences (falsification) or exit the public sphere entirely (selection)? Distinguishing between genuine legitimacy and measurement distortion is critical; misinterpreting the latter as the former risks validating authoritarian narratives of popular support.

This article develops and tests a "sensitivity gradient" framework to adjudicate between these possibilities without recourse to experimental design. While existing methods like list experiments are powerful, they cannot be applied retrospectively to the vast archives of standard survey data used to monitor global democracy. The sensitivity gradient approach fills this gap by exploiting a straightforward theoretical prediction: the cost of honest response under repression is not uniform but varies predictably across survey items.

I argue that high-sensitivity items—those evaluating specific coercive actors like the police or national government—are most susceptible to distortion. Respondents face strong incentives to feign support for these actors ("strategic compliance") or, in the case of critics, to self-select out of the survey pool entirely. Conversely, low-sensitivity items—such as abstract evaluations of "democracy" or "freedom"—often remain safer channels for expressive dissent, or at least carry lower penalties for non-compliance. If genuine support were rising, we should see uniform improvements across both domains. If measurement distortion is driving the data, we should observe a "gradient" of divergence: inflated support for coercive institutions coexisting with collapsing evaluations of the political environment.

I test this framework using a natural quasi-experiment created by the disruption of the Asian Barometer Survey (Wave 5) in Hong Kong. Fieldwork was split across the 2019 pro-democracy protests and the post-National Security Law (NSL) period, holding the instrument constant while the cost of dissent shifted exogenously. The analysis yields three findings. First, the sensitivity gradient predicts a "trust paradox": trust in the police surged ($d \approx +0.49$) while democratic suitability scores collapsed ($d = -0.54$), with the magnitude of inflation tracking each institution’s coercive role. Second, the canonical "critical citizens" correlation—whereby committed democrats express lower regime satisfaction—reverses in the post-NSL period. Third, this reversal is driven by "procedural democrats," a finding that challenges critical theoretical accounts suggesting authoritarian citizens simply possess distinct, non-liberal notions of democracy.

These findings contribute to three literatures. First, they refine the measurement of democratic backsliding [@Waldner2018-yw], offering a diagnostic tool for researchers working in closing spaces like Turkey, Russia, or Venezuela. Second, they engage debates on authoritarian legitimacy [@Nathan2003-rz; @Tang2016-pa; @Dukalskis2017-wf], providing empirical grounds to question whether "performance legitimacy" in autocracies is often an artifact of survey non-response and falsification. Finally, they bridge the gap between critical theory and survey methodology, operationalizing the concern that quantitative metrics can inadvertently reproduce the logic of domination by masking the silence of the marginalized.

# The Validity Problem in Autocratizing Regimes

## Survey Validity Under Political Pressure

The concern that survey measures may not mean the same thing in authoritarian and democratic contexts is not new. @Kuran1995-up's foundational work on preference falsification demonstrated that citizens under repressive regimes systematically misrepresent their private beliefs in public, generating a gap between stated and genuine preferences that can persist at equilibrium. @Wedeen1999-lk extended this insight by arguing that authoritarian regimes do not require genuine belief---only the public performance of compliance, such that "acting as if" one supports the regime becomes the regime's operative goal. @Simpser2013-ab demonstrates a parallel logic in the electoral domain: governments manipulate elections not merely to win but to signal dominance and convey the futility of resistance, a communicative function that applies equally to survey responses when citizens treat their answers as public acts rather than private disclosures. Empirical assessments of this phenomenon have proliferated in recent years. @Tannenberg2022-sc shows cross-nationally that respondents who believe the government commissioned a survey report systematically higher trust in autocracies but not in democracies, providing direct evidence that self-censorship inflates trust measures under authoritarian conditions. List experiments and endorsement experiments in China suggest that direct survey measures substantially overstate trust in sensitive institutions [@Nicholson2023-kt; @Blair2014-xl; @Bullock2011-kw]. @Jiang2016-hh exploit a political purge in China to show that responses to politically sensitive and insensitive survey items diverge following repressive events---an empirical strategy closely analogous to the present study. @Kobayashi2022-ih provide direct panel-level evidence from Hong Kong, demonstrating that pro-democracy respondents were more likely to drop out of political polls following the NSL, and that those who remained falsified potentially sensitive past behavior. More recently, @Shamaileh2025-hh demonstrates that nonresponse rates alone are insufficient proxies for preference falsification, since respondents under repression shift toward the regime-preferred response rather than simply declining to answer---a pattern consistent with @Simpser2013-ab's concept of strategic compliance, whereby citizens signal obedience through regime-favorable responses rather than merely withdrawing.

These studies establish that survey bias under authoritarianism is real and consequential. What remains underdeveloped is a framework for identifying bias *within* a given survey instrument without experimental manipulation. The sensitivity gradient approach proposed here fills this gap by exploiting a straightforward theoretical prediction: because the cost of honest response varies across items as a function of their political sensitivity, preference falsification should operate *differentially* within the same survey. Trust in the police---the institution most directly associated with coercive enforcement---should be the most inflated; trust in the judiciary, which retains some independence, should be less affected; abstract democratic evaluations, which do not directly implicate specific institutions, should remain comparatively honest. This differential generates testable predictions about the *pattern* of observed shifts, allowing analysts working with standard survey batteries to distinguish falsification from genuine attitude change without recourse to designed experiments.

## The "Critical Citizens" Paradigm and Its Assumptions

The "critical citizens" framework [@Norris2011-zt; @Easton1975-bg; @Dalton1984-bt] holds that citizens in consolidated democracies combine commitment to democratic ideals with dissatisfaction toward democratic performance. The empirical signature is a negative correlation between democratic support (valuing democracy) and democratic satisfaction (rating one's own democracy favorably). This relationship has been documented across OECD countries and many developing democracies, and it underpins a substantial body of comparative research on democratic quality and regime legitimacy [@Offe2006-dc; @Claassen2020-hk].

The framework rests on an implicit assumption that has received insufficient scrutiny: that respondents can express both democratic commitment and regime dissatisfaction without significant cost. In stable democracies, this assumption holds---stating that one values democracy while criticizing the government carries no meaningful risk. Under authoritarian consolidation, however, the assumption breaks down asymmetrically. Expressing regime dissatisfaction becomes costly (potentially dangerous), while expressing democratic commitment may remain relatively safe (or may even become a form of strategic signaling, as when respondents affirm that "democracy is always preferable" to demonstrate compliance with the regime's self-described democratic identity). This asymmetric cost structure predicts that the canonical negative correlation should weaken and potentially reverse under repression---not because citizens have changed their values, but because the cost structure of survey response has changed. If the correlation *does* flip positive, it provides a diagnostic signal that the survey environment has crossed a threshold beyond which standard interpretive frameworks no longer apply.

This possibility connects to broader concerns about how institutional environments shape the meaning of survey responses [@Schedler2013-qp; @Offe2006-dc] and, more specifically, to @Kirsch2019-vu's finding that "authoritarian notions of democracy"---in which citizens associate democracy with strong, unaccountable leadership rather than liberal-procedural governance---are widespread in autocracies and can reverse the substantive meaning of expressed democratic support. Distinguishing between genuine conceptual redefinition and strategic response distortion requires disaggregation by respondents' specific conception of democracy, a test I report in Section 4.3.

## Existing Approaches to the Measurement Problem

Methodologists have developed several tools for detecting preference falsification in survey data, including list experiments [@Blair2012-fa], endorsement experiments [@Blair2014-xl; @Bullock2011-kw], randomized response techniques [@Warner1965-dj], and the analysis of survey timing relative to political shocks [@Jiang2016-hh]. Each has important limitations for the problem at hand. List and endorsement experiments require prospective design---they cannot be applied retrospectively to data already collected. Survey timing analysis, while powerful, typically lacks the within-instrument variation needed to distinguish genuine attitude change from measurement distortion [@Schedler2013-qp]. Non-response diagnostics, as @Shamaileh2025-hh demonstrates, provide at best a lower bound on falsification, since the most common response to repression is not refusal but strategic compliance.

The sensitivity gradient approach complements these tools by exploiting within-instrument variation in item sensitivity. It requires no experimental design, works with standard cross-national survey batteries, and can be applied retrospectively to any survey fielded during a period of political change. The approach generates two portable diagnostics: first, the sensitivity gradient itself (whether observed shifts correlate with pre-specified item sensitivity rankings), and second, the correlation diagnostic (whether the standard critical citizens relationship reverses). Both can be computed from data already available in the ABS, World Values Survey, Afrobarometer, and Latinobarómetro archives, making the framework immediately applicable beyond the present case.

# Research Design: A Natural Quasi-Experiment

## The ABS Wave 5 Disruption as Identification Strategy

The identification strategy exploits an unintended natural experiment created by COVID-19 disruptions to Asian Barometer Survey fieldwork. In Hong Kong, Wave 5 interviews were conducted in two distinct clusters: a protest-period sample (October 2019--January 2020, $N = 473$) collected during the height of the Anti-Extradition Bill protests, and a post-NSL sample (March--May 2021, $N = 676$) collected after the National Security Law had been in force for nine months. A small number of interviews conducted during the gap period (February 2020--February 2021) are excluded due to ambiguous political context. The two sub-samples answered the same instrument under radically different costs of dissent: by March 2021, the NSL had criminalized a broad range of political expression, dozens of civil society organizations had dissolved, opposition legislators had been disqualified or arrested, and independent media outlets had shuttered.

This design is not a true experiment---respondents were not randomly assigned to periods. Compositional differences between the two samples may contribute to observed differences, a concern addressed through covariate adjustment, entropy balancing, and the analysis of differential non-response patterns in Section 4. The design's strength lies in holding the survey instrument, country, and survey wave constant while the political environment shifted dramatically, providing unusual leverage for the sensitivity gradient test.

To contextualize Hong Kong's shifts, I position the territory relative to fifteen other ABS Wave 5 polities using cross-national z-scores. Taiwan serves as a particularly informative comparison case: the two Chinese-speaking societies occupied similar positions on many democratic attitude indicators in Wave 4 but diverged sharply by Wave 5, with Taiwan consolidating democratically while Hong Kong's institutions were dismantled [@Huang2024-sy].

## Variables, Measurement, and the Sensitivity Gradient

The analysis examines variables spanning several domains of democratic attitudes, each classified by its expected position on the sensitivity gradient.

*High-sensitivity items* evaluate specific institutions with coercive capacity. Trust in the police, national government, president/chief executive, and military are coded on 1--4 scales. These items require respondents to directly assess institutions that wield enforcement power, making critical responses most politically costly under repression.

*Moderate-sensitivity items* assess governance perceptions and system evaluation. Freedom to organize, freedom of speech, government responsiveness, electoral fairness, and system support/pride are coded on 1--4 scales. These items are less directly tied to specific coercive actors but still implicate the political order.

*Lower-sensitivity items* capture abstract democratic evaluations. Democracy suitability (1--10 scale), extent of current democracy, democratic commitment (three-point scale), and democratic satisfaction fall in this category. While politically relevant, these items assess general orientations rather than specific institutional evaluations, reducing the perceived risk of honest response.

*Benchmark items* with minimal expected sensitivity include perceptions of equal treatment (rich/poor equality), general political interest, and trust in courts. Trust in courts occupies an interesting intermediate position: while formally part of the institutional landscape, the judiciary retained partial independence during the post-NSL transition and was less directly associated with street-level repression.

The sensitivity gradient predicts that preference falsification should produce the largest regime-favorable shifts on high-sensitivity items and the smallest (or regime-unfavorable) shifts on lower-sensitivity items. This within-instrument divergence is the core observable implication of the framework.

## Analytical Strategy

The analysis proceeds in four stages, each motivated by the theoretical framework. First, cross-national trajectory plots for key indicators across ABS Waves 1--5 position Hong Kong relative to Taiwan, Singapore, and the regional mean, establishing Hong Kong as the most extreme outlier in Wave 5 and justifying the single-case focus. Second, cross-national z-scores quantify Hong Kong's outlier status across thirteen indicators. Third, pre/post NSL comparisons within Wave 5 test the sensitivity gradient prediction, reporting Cohen's $d$ effect sizes, two-sample $t$-tests, covariate-adjusted OLS estimates, and entropy-balanced reweighted estimates. Fourth, the critical citizens correlation is computed for all fifteen Wave 5 polities and decomposed by fieldwork period and respondent conception of democracy within Hong Kong, testing whether the correlation diagnostic identifies measurement distortion.

All estimates incorporate ABS-provided post-stratification weights. Robustness checks include non-parametric Mann-Whitney $U$ tests (Online Appendix B), stratified percentile bootstrap with 5,000 iterations and BCa confidence intervals (Online Appendix D.1), Benjamini-Hochberg false discovery rate corrections (Online Appendix E.2), and Manski-style bounding exercises for both trust in police and trust in the national government (Online Appendix D.2). Full variable definitions with ABS Wave 5 item codes and response scales are reported in Online Appendix A.

# Results

## Hong Kong's Outlier Status: Justifying the Case

@fig-trajectories displays trajectory plots for six key democratic attitude indicators across ABS Waves 1--5, comparing Hong Kong, Taiwan, Singapore, and the regional mean. The most striking pattern is the Hong Kong--Taiwan divergence beginning in Wave 4 and widening sharply in Wave 5. On democracy suitability, the two polities stood at near-identical levels in Wave 3; by Wave 5, they had diverged by several points on a ten-point scale. Cross-national z-scores confirm Hong Kong's extreme outlier status in Wave 5, with z-scores reaching $+3.18$ on perceived democratic deficit and exceeding $\pm2$ on most indicators.

```{r}
#| label: fig-trajectories
#| fig-cap: "Key democratic attitude trajectories across ABS Waves 1–5. Hong Kong (red), Taiwan (blue), Singapore (green), and regional mean (grey dashed)."
#| fig-width: 14
#| fig-height: 9

library(patchwork)

focus_colors <- c(
  "Hong Kong" = "#E53935",
  "Taiwan" = "#1E88E5",
  "Singapore" = "#43A047",
  "Regional mean" = "#9E9E9E"
)

focus_shapes <- c(
  "Hong Kong" = 16,
  "Taiwan" = 15,
  "Singapore" = 17,
  "Regional mean" = 18
)

build_trajectory <- function(data, var, focus = c("Hong Kong", "Taiwan", "Singapore")) {
  focus_means <- data |>
    filter(country_name %in% focus, wave <= 5) |>
    group_by(country_name, wave) |>
    summarise(mean = mean(!!sym(var), na.rm = TRUE), .groups = "drop")

  regional <- data |>
    filter(!country_name %in% focus, wave <= 5) |>
    group_by(wave) |>
    summarise(mean = mean(!!sym(var), na.rm = TRUE), .groups = "drop") |>
    mutate(country_name = "Regional mean")

  bind_rows(focus_means, regional) |>
    mutate(country_name = factor(country_name,
      levels = c("Hong Kong", "Taiwan", "Singapore", "Regional mean")))
}

traj_vars <- list(
  list(var = "democracy_suitability", title = "Democracy Suitability (1-10)"),
  list(var = "trust_president", title = "Trust in President/CE (1-4)"),
  list(var = "trust_police", title = "Trust in Police (1-4)"),
  list(var = "gov_free_to_organize", title = "Freedom to Organize (1-4)"),
  list(var = "dem_free_speech", title = "Free to Speak Without Fear (1-4)"),
  list(var = "system_needs_change", title = "System Needs Major Change (1-4)")
)

make_traj_panel <- function(var, title) {
  df <- build_trajectory(d, var)
  ggplot(df, aes(x = wave, y = mean, color = country_name, shape = country_name)) +
    geom_line(aes(linetype = country_name), linewidth = 1) +
    geom_point(size = 3) +
    scale_color_manual(values = focus_colors) +
    scale_shape_manual(values = focus_shapes) +
    scale_linetype_manual(values = c("solid", "solid", "solid", "dashed")) +
    scale_x_continuous(breaks = 1:5, labels = paste0("W", 1:5)) +
    labs(title = title, x = NULL, y = NULL, color = NULL, shape = NULL, linetype = NULL) +
    theme_minimal(base_size = 11) +
    theme(legend.position = "none",
          plot.title = element_text(face = "bold", size = 10))
}

panels <- map2(
  map_chr(traj_vars, "var"),
  map_chr(traj_vars, "title"),
  make_traj_panel
)

panels[[1]] <- panels[[1]] + theme(legend.position = "bottom")

wrap_plots(panels, ncol = 3) +
  plot_annotation(
    title = "Hong Kong's Democratic Erosion in Comparative Context",
    subtitle = "Asian Barometer Survey, Waves 1-5",
    theme = theme(
      plot.title = element_text(face = "bold", size = 14),
      plot.subtitle = element_text(size = 11)
    )
  )
```

This cross-national positioning justifies the single-case focus: Hong Kong represents the extreme case of the measurement problem this article addresses. Where political change is most dramatic, the question of whether survey shifts reflect genuine attitudes or measurement distortion is most consequential.

## The Sensitivity Gradient in Action

The sensitivity gradient framework generates a clear prediction for the within-wave comparison: if preference falsification drives the observed shifts, the largest regime-favorable movements should appear on high-sensitivity items (trust in coercive institutions), while lower-sensitivity items (democratic evaluations) should shift against the regime or remain stable. @tbl-nsl reports the full set of pre/post NSL comparisons, and @tbl-sensitivity-gradient presents the pre-specified sensitivity ranking alongside observed effect sizes.

```{r}
#| label: tbl-nsl

nsl_label_map <- c(
  democracy_suitability = "Democracy Suitability",
  dem_extent_current = "Current Extent of Democracy",
  dem_country_present_govt = "Rate Govt as Democratic",
  dem_always_preferable = "Democracy Always Preferable",
  democracy_satisfaction = "Democratic Satisfaction",
  trust_national_government = "Trust in National Government",
  trust_president = "Trust in President/CE",
  trust_parliament = "Trust in Parliament",
  trust_police = "Trust in Police",
  trust_military = "Trust in Military",
  trust_courts = "Trust in Courts",
  gov_free_to_organize = "Freedom to Organize",
  dem_free_speech = "Free to Speak Without Fear*",
  govt_responds_people = "Govt Responds to People",
  election_free_fair = "Elections Free and Fair",
  system_deserves_support = "System Deserves Support",
  system_proud = "Proud of System",
  system_needs_change = "System Needs Major Change",
  strongman_rule = "Support Strongman Rule",
  military_rule = "Support Military Rule",
  single_party_rule = "Support Single-Party Rule",
  rich_poor_treated_equally = "Rich/Poor Treated Equally",
  political_interest = "Political Interest",
  nat_willing_emigrate = "Willingness to Emigrate",
  efficacy_ability_participate = "Ability to Participate",
  efficacy_no_influence = "No Influence on Govt",
  pol_discuss = "Discuss Politics",
  gov_opposition_opportunities = "Opposition Opportunities",
  gov_courts_powerless = "Courts Powerless"
)

nsl_tests |>
  mutate(
    label = ifelse(variable %in% names(nsl_label_map),
                   nsl_label_map[variable], variable)
  ) |>
  select(label, protest_mean, postnsl_mean, delta, cohens_d, p_value, sig) |>
  mutate(
    across(c(protest_mean, postnsl_mean, delta, cohens_d), ~round(.x, 3)),
    p_value = format.pval(p_value, digits = 3)
  ) |>
  kable(
    col.names = c("Variable", "Pre Mean", "Post Mean",
                   "Delta", "d", "p", ""),
    booktabs = TRUE,
    caption = "Pre/Post NSL comparison within Hong Kong Wave 5. Effect sizes (Cohen's d) and significance levels."
  ) |>
  kable_styling(latex_options = c("hold_position"), font_size = 9) |>
  column_spec(1, width = "3.8cm") |>
  footnote(
    symbol = "Higher values indicate more perceived freedom of speech. The positive post-NSL shift (respondents claiming more free speech) is consistent with preference falsification.",
    general = "Cohen's d computed as (Post-NSL - Protest) / pooled SD; positive values indicate higher post-NSL responses.",
    general_title = "Note: ",
    footnote_as_chunk = TRUE
  )
```

```{r}
#| label: fig-sensitivity-gradient
#| fig-cap: "Sensitivity gradient: Post-NSL effect sizes (Cohen's *d*) by survey item, ordered by pre-specified sensitivity to preference falsification. Dashed line: OLS fit. Error bars: 95% confidence intervals."
#| fig-width: 6.5
#| fig-height: 4.5

gradient_items <- tribble(
  ~variable, ~label, ~sensitivity_rank, ~category,
  "trust_police",              "Trust in Police",           1, "High",
  "trust_national_government", "Trust in Natl Government",  2, "High",
  "trust_president",           "Trust in President/CE",     3, "High",
  "trust_military",            "Trust in Military",         4, "Medium",
  "trust_parliament",          "Trust in Parliament",       5, "Medium",
  "trust_courts",              "Trust in Courts",           6, "Medium",
  "gov_free_to_organize",      "Freedom to Organize",       7, "Low",
  "dem_free_speech",           "Free to Speak Without Fear", 8, "Low",
  "democracy_suitability",     "Democracy Suitability",     9, "Low"
)

gradient_plot_data <- gradient_items |>
  left_join(
    nsl_tests |> select(variable, cohens_d, protest_n, postnsl_n),
    by = "variable"
  ) |>
  mutate(
    se_d = sqrt(1/protest_n + 1/postnsl_n + cohens_d^2 / (2*(protest_n + postnsl_n))),
    ci_lo = cohens_d - 1.96 * se_d,
    ci_hi = cohens_d + 1.96 * se_d,
    label = factor(label, levels = rev(label)),
    category = factor(category, levels = c("High", "Medium", "Low"))
  )

fit <- lm(cohens_d ~ sensitivity_rank, data = gradient_plot_data)
gradient_plot_data$fitted <- predict(fit)

cat_colors <- c(High = "#C62828", Medium = "#F57C00", Low = "#1565C0")
cat_shapes <- c(High = 16, Medium = 15, Low = 17)

ggplot(gradient_plot_data, aes(x = cohens_d, y = label)) +
  geom_vline(xintercept = 0, linetype = "solid", color = "grey70", linewidth = 0.4) +
  geom_line(aes(x = fitted, y = label, group = 1),
            linetype = "dashed", color = "grey50", linewidth = 0.5) +
  geom_errorbarh(aes(xmin = ci_lo, xmax = ci_hi, color = category),
                 height = 0.2, linewidth = 0.4) +
  geom_point(aes(color = category, shape = category), size = 2.5) +
  scale_color_manual(values = cat_colors, name = "Sensitivity") +
  scale_shape_manual(values = cat_shapes, name = "Sensitivity") +
  labs(x = "Cohen's *d* (Post-NSL minus Protest)", y = NULL) +
  theme_minimal(base_size = 11) +
  theme(
    axis.title.x = ggtext::element_markdown(),
    legend.position = "bottom",
    panel.grid.major.y = element_blank(),
    panel.grid.minor = element_blank()
  )
```

@fig-sensitivity-gradient visualizes the sensitivity gradient prediction, which the data confirm with striking precision. Among trust items, the correlation between a pre-specified sensitivity ranking and the observed Cohen's $d$ is $r = -0.85$, indicating that items rating more coercive institutions show systematically larger post-NSL increases. Trust in police ($d = 0.43$) and the national government ($d = 0.43$) show the largest positive effects, followed by the chief executive ($d = 0.38$) and parliament ($d = 0.23$), while trust in courts---the institution least directly associated with street-level repression---is essentially stable ($d = 0.03$).

```{r}
#| label: tbl-sensitivity-gradient
#| tbl-cap: "Institutional sensitivity gradient: pre-specified ranking and observed effect sizes."

sensitivity_ranking <- tribble(
  ~Institution, ~`Sensitivity Rank`, ~Rationale, ~variable,
  "Police", 1, "Primary coercive agent during protests", "trust_police",
  "National Government", 2, "Enacted and enforced NSL", "trust_national_government",
  "President/CE", 3, "Chief executive implementing NSL", "trust_president",
  "Military", 4, "PLA garrison; visible but not street-deployed", "trust_military",
  "Parliament", 5, "Restructured but less directly coercive", "trust_parliament",
  "Courts", 6, "Retained partial independence", "trust_courts"
)

trust_ds <- nsl_tests |>
  filter(variable %in% sensitivity_ranking$variable) |>
  select(variable, cohens_d)

gradient <- sensitivity_ranking |>
  left_join(trust_ds, by = "variable") |>
  arrange(`Sensitivity Rank`)

r_gradient <- cor(gradient$`Sensitivity Rank`, gradient$cohens_d)

gradient |>
  select(Institution, `Sensitivity Rank`, Rationale, cohens_d) |>
  mutate(cohens_d = round(cohens_d, 3)) |>
  kable(
    col.names = c("Institution", "Rank", "Rationale", "d"),
    booktabs = TRUE
  ) |>
  kable_styling(latex_options = c("hold_position"), font_size = 10) |>
  column_spec(1, width = "2.5cm") |>
  column_spec(2, width = "1cm") |>
  column_spec(3, width = "5.5cm") |>
  column_spec(4, width = "1cm") |>
  footnote(
    general = paste0(
      "Sensitivity ranking derived from the theoretical framework (Section 2.1) ",
      "based on each institution's direct association with coercive enforcement. ",
      "Rankings were specified prior to examining effect sizes. ",
      "Spearman correlation between rank and d: r = ", round(r_gradient, 2), "."
    ),
    general_title = "Note: ",
    footnote_as_chunk = TRUE
  )
```

This ordering cannot be explained by compositional selection alone, which would predict uniform shifts across all trust items---critics leaving the sample should reduce criticism of all institutions equally. Instead, the gradient is consistent with preference falsification operating differentially: respondents who remain in the sample calibrate their reported trust to the perceived political risk of each item.

The divergent movement of trust and democratic evaluation provides further diagnostic evidence. While trust in coercive institutions surged, democracy suitability fell by over half a standard deviation ($d = -0.54$), freedom to organize declined significantly, and the share of respondents rating elections as free and fair dropped. This simultaneous increase in institutional trust and decline in democratic evaluation is the signature the sensitivity gradient framework predicts: high-sensitivity items inflate while lower-sensitivity items continue to track genuine sentiment. Covariate-adjusted OLS estimates and entropy-balanced reweighted estimates yield substantively identical results (@tbl-adjusted), confirming that the observed shifts are not artifacts of compositional differences on observable demographics (see Online Appendix C for demographic balance tests across periods and Online Appendix G for HC2 robust standard errors).

```{r}
#| label: tbl-adjusted
#| tbl-cap: "Post-NSL effect estimates for four primary outcomes: unadjusted, covariate-adjusted (OLS with age, gender, and education level), and entropy-balanced."

if (exists("combined_table") && !is.null(combined_table)) {
  combined_table |>
    kable(
      col.names = c("Outcome",
                     "$b$", "SE", "$p$",
                     "$b$", "SE", "$p$",
                     "$b$", "SE", "$p$"),
      booktabs = TRUE,
      escape = FALSE
    ) |>
    kable_styling(latex_options = c("hold_position"), full_width = FALSE, font_size = 10) |>
    add_header_above(c(" " = 1, "Unadjusted" = 3, "Covariate-Adjusted" = 3, "Reweighted" = 3)) |>
    column_spec(1, width = "3.5cm")
} else if (exists("ols_results")) {
  ols_results |>
    mutate(across(c(b_unadj, se_unadj, b_adj, se_adj), ~round(.x, 3)),
           p_unadj = format.pval(p_unadj, digits = 3),
           p_adj = format.pval(p_adj, digits = 3)) |>
    select(label, b_unadj, se_unadj, p_unadj, b_adj, se_adj, p_adj, n_adj) |>
    kable(
      col.names = c("Outcome", "$b$", "SE", "$p$", "$b$", "SE", "$p$", "$N$"),
      booktabs = TRUE,
      escape = FALSE
    ) |>
    kable_styling(latex_options = c("hold_position"), full_width = FALSE, font_size = 10) |>
    column_spec(1, width = "3.5cm")
}
```

Two additional results sharpen the sensitivity gradient interpretation. Pre-specified placebo-adjacent items with lower expected political sensitivity show small or non-significant effects, consistent with NSL-specific mechanisms rather than generalized confounding (Online Appendix E.1). First, the item measuring agreement that people can "speak without fear" *increased* post-NSL ($d = +0.41$, $p < .001$)---a substantively implausible result in a context where the NSL had criminalized political expression. This implausible shift on a sensitive climate item, combined with the trust increases, is precisely the pattern preference falsification predicts: respondents inflate regime-favorable responses on items where the "wrong" answer is most conspicuously critical. Second, low-sensitivity benchmark items (political interest, rich/poor treated equally) showed small or non-significant effects, consistent with the theoretical expectation that these items are less subject to falsification pressure.

Differential item non-response provides additional evidence: trust items maintain near-identical response rates across periods while normative democracy items show a mean decline of 4.6 percentage points, consistent with politically motivated non-response on items requiring explicit democratic commitments (Online Appendix F). World Values Survey Wave 7, fielded in Hong Kong in 2018 before the crisis, provides an external baseline that further clarifies the sensitivity gradient interpretation. Pre-protest WVS means for police trust (2.70) and government trust (2.50) closely match the ABS post-NSL means (2.64 and 2.63), while ABS protest-period means fell well below both benchmarks. The post-NSL "recovery" thus represents reversion to the pre-protest baseline rather than a surge to new heights---consistent with falsification restoring the social desirability equilibrium rather than generating genuine new confidence. Trust in courts, by contrast, declined from a WVS baseline of 3.02 to 2.71 during the protests and remained depressed at 2.74 post-NSL, with no sign of recovery. Democracy suitability tells the opposite story: the WVS baseline of 7.83 fell to 6.94 during the protests and continued declining to 5.74 post-NSL, with no recovery. This V-shaped pattern for coercive institutions set against monotonic decline for evaluative items is precisely the differential trajectory predicted by the sensitivity gradient.

## The Diagnostic Power of the Flipped Correlation

The sensitivity gradient provides a quantitative test; the critical citizens correlation provides a qualitative diagnostic. In the standard framework, the negative correlation between democratic commitment and democratic satisfaction holds when respondents can express both honestly. When the correlation flips positive, it signals that one or both constructs are being distorted by asymmetric costs of honest response.

Among the fifteen polities with sufficient data in ABS Wave 5, Hong Kong is the only case with a substantively positive correlation between democratic commitment and democratic satisfaction ($r = 0.279$, 95% CI [0.221, 0.336], $N = 980$). Singapore shows a near-zero positive value ($r = 0.013$); all other countries are negative. The reversal intensifies when decomposed by fieldwork period: the correlation is weaker during the protest period ($r = 0.184$) and strengthens markedly in the post-NSL period ($r = 0.328$), consistent with a mechanism that operates more strongly under authoritarian constraint.

A more informative decomposition separates respondents by their conception of democracy, using the ABS forced-choice item asking which element is most essential. Respondents who selected substantive elements (basic necessities or clean governance) show a near-zero correlation between democratic preference and democratic satisfaction in both periods (protest: $r = 0.059$, $N = 211$, $p = .40$; post-NSL: $r = 0.056$, $N = 231$, $p = .40$). By contrast, respondents who selected procedural elements (free expression or free elections) show a modest non-significant correlation during the protest period ($r = 0.095$, $N = 193$, $p = .19$) that strengthens dramatically post-NSL ($r = 0.355$, $N = 289$, $p < .001$). A Fisher $z$-test confirms the post-NSL difference between groups ($z = 3.55$, $p < .001$). Online Appendix E.4 provides a finer decomposition by specific essential element, and Online Appendix E.2 reports the cross-national comparison confirming Hong Kong as the sole positive case.

This decomposition is the key test distinguishing between competing accounts. If the @Kirsch2019-vu co-optation mechanism---in which regimes redefine "democracy" to include authoritarian characteristics---were driving the reversal, it should be concentrated among substantive-conception respondents, whose values align with the regime's "stability and order" narrative. Instead, the reversal is concentrated among procedural democrats, those whose democratic ideal explicitly centers on the freedoms most visibly curtailed by the NSL. This pattern is most consistent with a selection-falsification mechanism: procedural democrats who remained in the post-NSL sample and continued to endorse "democracy is always preferable" were simultaneously inflating their satisfaction responses, either because they feared the consequences of expressing dissatisfaction or because the most critical procedural democrats had already selected out of the sample through emigration or survey refusal. Under either interpretation, the positive correlation does not indicate genuine democratic satisfaction but reflects the distortion of survey responses under authoritarian constraint.

## Triangulation Evidence

Independent evidence from other survey sources corroborates the sensitivity gradient interpretation. Using online panel data collected before and after the NSL, @Kobayashi2022-ih found that pro-democracy respondents subject to political repression were more likely to drop out of political polls, and that those who remained falsified potentially sensitive past behavior---providing direct panel-level evidence for both compositional selection and preference falsification. @Yang2023-dd used HKPORI tracking data with synthetic difference-in-differences to demonstrate a significant differential treatment effect on politically sensitive poll items compared to less sensitive items following the NSL's implementation, a pattern closely analogous to the sensitivity gradient documented above.

Compositional selection is further supported by emigration data. The ABS survey item measuring willingness to emigrate shows a significant shift between fieldwork periods, and administrative data confirm that this contemplation translated into actual exit at scale: the Hong Kong Census and Statistics Department recorded a net outflow of approximately 27,300 residents by end-2021, accelerating to 60,000 by end-2022 [@C-SD2022-vf; @Hong-Kong-Government2023-ub], while the UK Home Office reported over 230,000 BN(O) visas granted by early 2026 [@Home-Office2026-yz]. These outflows, combined with the within-wave evidence of shifting emigration intentions, confirm that a politically non-random subset of the population was exiting during and after the fieldwork period.

# Discussion

## What the Sensitivity Gradient Reveals

@tbl-mechanisms presents the observable implications of four competing interpretive accounts across the key empirical patterns. The sensitivity gradient framework successfully distinguishes among them.

```{r}
#| label: tbl-mechanisms
#| tbl-cap: "Observable implications of competing mechanisms for the trust paradox."

mech_table <- tibble(
  `Observable pattern` = c(
    "Trust up in post-NSL period",
    "Democracy suitability down",
    "Emigration intentions shift",
    "Age gradient in trust",
    "Trust up and dem. evaluation down simultaneously",
    "Trust in courts stable (d = 0.03)",
    "Reported free speech up while trust up",
    "Procedural dem. conception up",
    "China rated more democratic"
  ),
  `Preference falsification` = c(
    "Consistent (fear-driven reporting)",
    "Ambiguous (less sensitive item)",
    "Neutral",
    "Consistent (young more surveilled/targeted)",
    "Consistent (differential item sensitivity)",
    "Consistent (courts less politically salient)",
    "Consistent (inflated claim of freedom)",
    "Neutral",
    "Consistent (strategic signaling of loyalty)"
  ),
  `Compositional selection` = c(
    "Consistent (critics drop out/emigrate)",
    "Inconsistent (should also rise if critics leave)",
    "Consistent (direct evidence of exit)",
    "Consistent (young more likely to emigrate/refuse)",
    "Partial (predicts both shift same direction)",
    "Ambiguous",
    "Partial (critics who reported less freedom left)",
    "Inconsistent (no reason conceptions shift)",
    "Partial (pro-Beijing stayers)"
  ),
  `Conservative revaluation` = c(
    "Consistent (sincerely welcome order)",
    "Consistent (recognize erosion, approve of it)",
    "Neutral",
    "Consistent (strongest in 60+ cohort)",
    "Consistent (coherent conservative worldview)",
    "Partial (less reason to revalue courts)",
    "Inconsistent (no reason to claim more freedom)",
    "Inconsistent (predicts weaker procedural commitment)",
    "Partial (genuine belief revision)"
  ),
  `Diffuse attitude change` = c(
    "Inconsistent (no broad performance improvement)",
    "Consistent (recognizing erosion)",
    "Neutral",
    "Consistent (generational value differences)",
    "Inconsistent (no reason for divergent movement)",
    "Ambiguous",
    "Inconsistent (implausible genuine increase)",
    "Inconsistent (predicts weaker dem. commitment)",
    "Ambiguous (info environment shift)"
  )
)

mech_table |>
  kable(booktabs = TRUE) |>
  kable_styling(latex_options = c("scale_down", "hold_position")) |>
  column_spec(1, width = "3.2cm") |>
  column_spec(2:5, width = "3cm")
```

The key discriminating patterns are the divergent movement of trust and democratic evaluation, which rules out compositional selection as the sole mechanism (it predicts both indicators shifting in the same direction); the implausible increase in reported free speech, which rules out conservative revaluation as a complete account; and the sensitivity gradient ordering itself, which rules out acquiescence bias (uniform inflation would not produce the observed rank-order correlation). The most parsimonious interpretation combines preference falsification with compositional selection, with genuine conservative revaluation accounting for some portion of the trust increase, particularly among older respondents (see Online Appendix D.3 for age-stratified pre/post NSL shifts). This interpretation does not deny the possibility of authentic regime support---a substantial literature documents the mechanisms through which autocracies cultivate genuine legitimacy, including communicative strategies of regime justification [@Dukalskis2017-wf], soft propaganda that can shift real attitudes [@Mattingly2022-gz], and culturally embedded preferences for order and stability [@Tang2016-pa]. The sensitivity gradient framework does not claim that all measured support is false; rather, it provides a diagnostic for identifying when the balance between genuine and distorted support has tipped sufficiently to undermine the validity of standard survey interpretations.

## Alternative Explanations and Boundary Conditions

Several alternative accounts warrant consideration. A COVID-19 rally effect may contribute to the trust increase, but the coexistence of rising trust with declining democracy suitability is inconsistent with a generalized rally effect, which should elevate both. Information environment restructuring, driven by the closure of independent media between fieldwork periods, may have altered respondents' frames of reference---a mechanism consistent with research on how autocracies shape public opinion through media control [@Mattingly2022-gz; @Guriev2020-cu]; post-NSL respondents rated China as substantially more democratic ($d = +0.47$), suggesting shifted reference points. This mechanism is conceptually distinct from Kuran-style preference falsification---it implies altered belief formation rather than strategic misrepresentation---though both produce similar observable implications in survey data.

The sensitivity gradient approach has identifiable boundary conditions. It works best when repression is uneven across institutional domains, creating within-instrument variation in item sensitivity. In regimes with uniform totalitarian control, all items may be equally sensitive, eliminating the gradient. The approach also requires a period of rapid political change to generate observable pre/post differences; it is less informative for regimes with stable, long-standing authoritarian control where falsification equilibria have already been reached. Finally, the approach identifies *patterns* consistent with falsification but cannot precisely decompose the relative contributions of falsification, selection, and genuine attitude change without supplementary experimental evidence.

## Implications for Comparative Survey Research

The findings carry concrete implications for scholars working with survey data in autocratizing contexts.

First, researchers using ABS, World Values Survey, Afrobarometer, or Latinobarometro data in regimes undergoing democratic erosion should apply sensitivity gradient checks before interpreting observed attitude shifts at face value. If high-sensitivity items (trust in coercive institutions) show larger regime-favorable shifts than low-sensitivity items (abstract democratic evaluations), the observed trust increase may reflect measurement distortion rather than genuine legitimacy gains. The within-instrument divergence documented here, with trust in police increasing by half a standard deviation while democracy suitability declined by a comparable magnitude, provides a benchmark for the magnitude of distortion possible during rapid autocratization.

Second, the flipped correlation diagnostic can be applied to any survey containing both democratic commitment and regime satisfaction items. When the standard negative correlation reverses, it signals that the cost structure of honest survey response has crossed a threshold beyond which standard interpretive frameworks no longer apply. Researchers interpreting cross-national variation in the critical citizens relationship should, at minimum, condition on the political conditions of survey administration and attend to whether positive correlations cluster in repressive contexts. The decomposition by democratic conception type provides additional leverage: if the reversal is concentrated among procedural democrats rather than substantive-conception respondents, co-optation is unlikely to be the dominant mechanism.

Third, existing findings in the backsliding literature that rely on post-repression survey data may warrant reinterpretation. Research on the relationship between public support and democratic survival [@Claassen2020-hk] and on how polarization shapes regime support [@Davis2025-cps] depends on the assumption that survey measures capture genuine attitudes rather than strategic responses. When international observers and scholars interpret survey-based legitimacy claims at face value, they may inadvertently reinforce the informational strategies that autocracies deploy [@Bush2017-io; @Dukalskis2017-wf]. Cross-national studies reporting elevated trust or satisfaction in autocratizing regimes, including work drawing on data from Myanmar post-2021, Turkey post-2016, and Russia post-2022, should consider whether the observed levels reflect genuine attitudes or the sensitivity gradient dynamics documented here. Online Appendix H applies the sensitivity gradient to World Values Survey data from Turkey and Russia, demonstrating that the same pattern---democracy items exhibiting systematically higher non-response than trust items, which in turn exceed apolitical controls---emerges independently across both contexts. The framework is immediately applicable: sensitivity rankings can be constructed for trust items in any cross-national survey battery, and the correlation diagnostic requires only democratic commitment and satisfaction items that are standard across all major survey programs. As scholars continue to debate whether democratic backsliding constitutes a global trend or a measurement artifact [@Waldner2018-yw], the sensitivity gradient provides a concrete tool for adjudicating between these possibilities at the case level.

## Limitations

The within-wave comparison is a quasi-experiment, not a true experiment. Respondents were not randomly assigned to fieldwork periods, and the gap period complicates attribution to the NSL specifically. The analysis cannot determine the precise mix of preference falsification and compositional selection, nor cleanly separate the NSL's contribution from concurrent shocks. The sub-sample sizes ($N_{\text{Protest}} = 473$; $N_{\text{Post-NSL}} = 676$) are adequate for the moderate-to-large effects observed but limit the precision of subgroup analyses. Finally, the sensitivity gradient framework is tested primarily on a single case of rapid, externally imposed autocratization. Preliminary evidence from WVS data suggests the gradient generalizes to Turkey and Russia (Online Appendix H), but its applicability to gradual erosion from within, as in Hungary or Poland, remains to be established empirically.

# Conclusion

Surveys are essential tools for studying democratic backsliding, but they require validity checks calibrated to the political environment. This article has developed and tested a sensitivity gradient framework for identifying when survey measures in autocratizing regimes produce false positives for regime support. The framework exploits a simple theoretical insight: because the cost of honest response varies across survey items as a function of their political sensitivity, preference falsification generates a predictable within-instrument pattern of distortion. High-sensitivity items inflate in the regime-favorable direction; low-sensitivity items continue to track genuine sentiment. This divergence provides a diagnostic that requires no experimental design, works with standard survey batteries, and can be applied retrospectively to data already collected.

The Hong Kong case demonstrates both the framework's power and its urgency. When trust in police can increase by half a standard deviation in the months following mass police violence against protesters, the measure is capturing something other than genuine institutional confidence. The simultaneous collapse of democracy suitability, the reversal of the critical citizens correlation among procedural democrats, and the implausible increase in reported free speech converge on the same conclusion: the post-NSL survey environment produced systematic false positives for regime support on politically sensitive items. If scholars cannot distinguish these false positives from genuine attitude change, they risk misdiagnosing authoritarian consolidation as popular legitimacy---a consequential error for both academic understanding and policy response.

The sensitivity gradient approach does not resolve every measurement challenge in authoritarian survey research. It works best when repression is uneven, political change is rapid, and surveys contain items spanning a range of political sensitivity. But for the growing number of cases where these conditions obtain---not only Hong Kong but Myanmar, Turkey, Russia, and beyond---it offers an immediately applicable tool for assessing whether the data can be trusted to mean what it appears to say.

# References {.unnumbered}

\singlespacing

::: {#refs}
:::
