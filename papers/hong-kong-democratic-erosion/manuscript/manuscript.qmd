---
title: "When Do Surveys Produce False Positives for Regime Support? A Sensitivity Gradient Approach to Measurement Distortion in Autocratizing Regimes"
author:
  - name: Jeffrey Stark
    affiliations:
      - name: Yonsei University
        department: Department of Sociology
    email: jeffrey.stark@yonsei.ac.kr
    corresponding: true
date: "`r format(Sys.time(), '%B %d, %Y — %H:%M')`"
abstract: |
  Scholars of democratic backsliding rely on survey data to track regime legitimacy, yet the same repressive forces that dismantle institutions also distort the instruments used to measure public attitudes. This article develops a "sensitivity gradient" framework to identify measurement distortion—the aggregate effect of preference falsification and compositional selection—during authoritarian consolidation. I argue that under repression, survey reliability degrades along a predictable gradient: high-sensitivity items (e.g., trust in police) inflate due to strategic compliance and the exit of critics, while low-sensitivity items (e.g., abstract democratic values) remain comparatively robust. Testing this framework using a natural quasi-experiment in Hong Kong (the 2020 National Security Law), consistent with a measurement distortion account, the data reveal a "trust paradox": trust in police surged ($d \approx +0.49$) while perceived democratic suitability collapsed ($d = -0.54$). Furthermore, the canonical "critical citizens" correlation reverses, a diagnostic signal that standard survey relationships have broken down. A cross-national replication using World Values Survey data from Turkey—bracketing the 2016 coup attempt and subsequent authoritarian consolidation—suggests that the same gradient pattern emerges independently ($r = -0.68$), with trust in coercive institutions rising while democratic evaluations decline. Critically, the gradient does not appear in all autocratizing contexts: in Venezuela and Nicaragua, where institutional collapse was genuine and uniform, and in Burkina Faso, where the coup enjoyed popular support, the gradient is absent or inverted—providing discriminant validity for the framework. These findings challenge "authoritarian resilience" interpretations of rising trust, suggesting instead that autocratization generates systematic false positives for regime support specifically when repression is targeted and procedurally legitimated.
keywords:
  - survey measurement
  - autocratization 
  - preference falsification 
  - democratic backsliding 
  - Hong Kong
  - Turkey
  - comparative methodology
format:
  pdf:
    documentclass: article
    classoption: [12pt, letterpaper]
    geometry:
      - margin=1in
    linestretch: 2
    number-sections: true
    colorlinks: true
    keep-tex: true
    include-in-header:
      - text: |
          \usepackage{setspace}
          \usepackage{booktabs}
          \usepackage{caption}
          \usepackage{longtable}
          \usepackage{array}
          \usepackage{multirow}
          \usepackage{float}
          \usepackage{graphicx}
          \usepackage{threeparttable}
          \usepackage{threeparttablex}
          \captionsetup{width=\textwidth}
          \setlength\LTcapwidth{\textwidth}
          \floatplacement{figure}{H}
          \floatplacement{table}{H}
          \raggedright
  html:
    toc: true
    toc-depth: 3
    number-sections: true
    theme: cosmo
bibliography: references.bib
csl: chicago-author-date.csl
execute:
  echo: false
  warning: false
  message: false
---

```{r setup}
#| include: false
library(tidyverse)
library(knitr)
library(kableExtra)

knitr::opts_chunk$set(
  echo = FALSE, message = FALSE, warning = FALSE,
  fig.align = "center", fig.pos = "H", out.width = "100%"
)

# Load results from the HK analysis pipeline
results_path <- "../../hong-kong-democratic-erosion/analysis/results"

load(file.path(results_path, "prepared_data.RData"))
load(file.path(results_path, "descriptive_results.RData"))

if (file.exists(file.path(results_path, "main_analysis_results.RData"))) {
  load(file.path(results_path, "main_analysis_results.RData"))
}

if (file.exists(file.path(results_path, "robustness_results.RData"))) {
  load(file.path(results_path, "robustness_results.RData"))
}

if (file.exists(file.path(results_path, "alt_explanations_results.RData"))) {
  load(file.path(results_path, "alt_explanations_results.RData"))
}
```

# Introduction

Scholars of democratic erosion face a fundamental identification challenge: the same coercive forces that dismantle democratic institutions also reshape the conditions under which citizens evaluate them. As regimes consolidate control, cross-national surveys often record puzzling spikes in institutional trust and regime satisfaction. Do these shifts reflect genuine "authoritarian resilience" [@Nathan2003-wg] rooted in performance legitimacy and a preference for order? Or do they reflect measurement distortion—a mirage created when critics either hide their true preferences (falsification) or exit the public sphere entirely (selection)? Distinguishing between genuine legitimacy and measurement distortion is critical; misinterpreting the latter as the former risks validating authoritarian narratives of popular support.

This article develops and tests a "sensitivity gradient" framework to adjudicate between these possibilities without recourse to experimental design. While existing methods like list experiments are powerful, they cannot be applied retrospectively to the vast archives of standard survey data used to monitor global democracy. The sensitivity gradient approach fills this gap by exploiting a straightforward theoretical prediction: the cost of honest response under repression is not uniform but varies predictably across survey items.

I argue that high-sensitivity items—those evaluating specific coercive actors like the police or national government—are most susceptible to distortion. Respondents face strong incentives to feign support for these actors ("strategic compliance") or, in the case of critics, to self-select out of the survey pool entirely. Conversely, low-sensitivity items—such as abstract evaluations of "democracy" or "freedom"—often remain safer channels for expressive dissent, or at least carry lower penalties for non-compliance. If genuine support were rising, we should see uniform improvements across both domains. If measurement distortion is at work, we should observe a "gradient" of divergence: inflated support for coercive institutions coexisting with collapsing evaluations of the political environment.

I test this framework using a natural quasi-experiment created by the disruption of the Asian Barometer Survey (Wave 5) in Hong Kong. Fieldwork was split across the 2019 pro-democracy protests and the post-National Security Law (NSL) period, holding the instrument constant while the cost of dissent shifted exogenously. The analysis yields three findings. First, the sensitivity gradient predicts a "trust paradox": trust in the police surged ($d \approx +0.49$) while democratic suitability scores collapsed ($d = -0.54$), with the magnitude of inflation tracking each institution’s coercive role. Second, the canonical "critical citizens" correlation—whereby committed democrats express lower regime satisfaction—reverses in the post-NSL period. Third, this reversal is concentrated among "procedural democrats," a finding that challenges critical theoretical accounts suggesting authoritarian citizens simply possess distinct, non-liberal notions of democracy.

To assess whether the pattern generalizes, I apply the same framework to Turkey using World Values Survey data spanning the 2016 coup attempt, finding consistent evidence of differential item inflation across a different autocratization context and survey instrument (Section 4.6). I further adjudicate among competing mechanisms through age-stratified analysis, information environment tests, and rally effect diagnostics (Section 4.5), finding that no single alternative explanation accounts for all observed patterns. The framework is best suited to contexts where autocratization is rapid and survey fieldwork spans the transition, though cross-wave comparisons (as in Turkey) also reveal gradient patterns when waves bracket clear autocratization shocks. The approach requires only standard trust and democratic evaluation items available in all major cross-national survey programs.

These findings contribute to three literatures. First, they refine the measurement of democratic backsliding [@Waldner2018-yw], offering a diagnostic tool---replicated cross-nationally in Turkey---for researchers working in closing spaces.^[Preliminary evidence from published Levada Center tracking polls in Russia shows patterns consistent with the framework (trust increases coinciding with democratic support decreases around the February 2022 invasion of Ukraine), but individual-level microdata access would be required for the item-level diagnostics that constitute the key tests. Online Appendix J reports available WVS-based evidence for Russia, where Waves 6 (2011) and 7 (2017) bracket the post-Crimea annexation period rather than the 2022 invasion.] Second, they engage debates on authoritarian legitimacy [@Nathan2003-wg; @Tang2016-nl; @Dukalskis2017-md], providing empirical grounds to question whether "performance legitimacy" in autocracies is often an artifact of survey non-response and falsification. Finally, they bridge the gap between critical theory and survey methodology, operationalizing the concern that quantitative metrics can inadvertently reproduce the logic of domination by masking the silence of the marginalized.

# The Validity Problem in Autocratizing Regimes

## Survey Validity Under Political Pressure

The concern that survey measures may not mean the same thing in authoritarian and democratic contexts is not new. @Kuran1995-up's foundational work on preference falsification demonstrated that citizens under repressive regimes systematically misrepresent their private beliefs in public, generating a gap between stated and genuine preferences that can persist at equilibrium. @Wedeen2000-bg extended this insight by arguing that authoritarian regimes do not require genuine belief---only the public performance of compliance, such that "acting as if" one supports the regime becomes the regime's operative goal. @Simpser2013-pf demonstrates a parallel logic in the electoral domain: governments manipulate elections not merely to win but to signal dominance and convey the futility of resistance, a communicative function that applies equally to survey responses when citizens treat their answers as public acts rather than private disclosures. Empirical assessments of this phenomenon have proliferated in recent years. @Tannenberg2022-sc shows cross-nationally that respondents who believe the government commissioned a survey report systematically higher trust in autocracies but not in democracies, providing direct evidence that self-censorship inflates trust measures under authoritarian conditions. List experiments and endorsement experiments in China suggest that direct survey measures substantially overstate trust in sensitive institutions [@Nicholson2023-kt; @Blair2014-xl; @Bullock2011-kw]. @Jiang2016-hh exploit a political purge in China to show that responses to politically sensitive and insensitive survey items diverge following repressive events---an empirical strategy closely analogous to the present study. @Kobayashi2022-ih provide direct panel-level evidence from Hong Kong, demonstrating that pro-democracy respondents were more likely to drop out of political polls following the NSL, and that those who remained falsified potentially sensitive past behavior. More recently, @Shamaileh2025-hh demonstrates that nonresponse rates alone are insufficient proxies for preference falsification, since respondents under repression shift toward the regime-preferred response rather than simply declining to answer---a pattern consistent with @Simpser2013-pf's concept of strategic compliance, whereby citizens signal obedience through regime-favorable responses rather than merely withdrawing.

These studies establish that survey bias under authoritarianism is real and consequential. What remains underdeveloped is a framework for identifying bias *within* a given survey instrument without experimental manipulation. The sensitivity gradient approach proposed here fills this gap by exploiting a straightforward theoretical prediction: because the cost of honest response varies across items as a function of their political sensitivity, preference falsification should operate *differentially* within the same survey. Trust in the police---the institution most directly associated with coercive enforcement---should be the most inflated; trust in the judiciary, which retains some independence, should be less affected; abstract democratic evaluations, which do not directly implicate specific institutions, should remain comparatively honest. This differential generates testable predictions about the *pattern* of observed shifts, allowing analysts working with standard survey batteries to distinguish falsification from genuine attitude change without recourse to designed experiments.

## The "Critical Citizens" Paradigm and Its Assumptions

The "critical citizens" framework [@Norris2011-oc; @Easton1975-bg; @Dalton1984-bt] holds that citizens in consolidated democracies combine commitment to democratic ideals with dissatisfaction toward democratic performance. The empirical signature is a negative correlation between democratic support (valuing democracy) and democratic satisfaction (rating one's own democracy favorably). This relationship has been documented across OECD countries and many developing democracies, and it underpins a substantial body of comparative research on democratic quality and regime legitimacy [@Offe2008-xz; @Claassen2020-hk].

The framework rests on an implicit assumption that has received insufficient scrutiny: that respondents can express both democratic commitment and regime dissatisfaction without significant cost. In stable democracies, this assumption holds---stating that one values democracy while criticizing the government carries no meaningful risk. Under authoritarian consolidation, however, the assumption breaks down asymmetrically. Expressing regime dissatisfaction becomes costly (potentially dangerous), while expressing democratic commitment may remain relatively safe (or may even become a form of strategic signaling, as when respondents affirm that "democracy is always preferable" to demonstrate compliance with the regime's self-described democratic identity). This asymmetric cost structure predicts that the canonical negative correlation should weaken and potentially reverse under repression---not because citizens have changed their values, but because the cost structure of survey response has changed. If the correlation *does* flip positive, it provides a diagnostic signal that the survey environment has crossed a threshold beyond which standard interpretive frameworks no longer apply.

This possibility connects to broader concerns about how institutional environments shape the meaning of survey responses [@Schedler2013-qn; @Offe2008-xz] and, more specifically, to @Kirsch2019-vu's finding that "authoritarian notions of democracy"---in which citizens associate democracy with strong, unaccountable leadership rather than liberal-procedural governance---are widespread in autocracies and can reverse the substantive meaning of expressed democratic support. Distinguishing between genuine conceptual redefinition and strategic response distortion requires disaggregation by respondents' specific conception of democracy, a test I report in Section 4.3.

## Existing Approaches to the Measurement Problem

Methodologists have developed several tools for detecting preference falsification in survey data, including list experiments [@Blair2012-fa], endorsement experiments [@Blair2014-xl; @Bullock2011-kw], randomized response techniques [@Warner1965-dj], and the analysis of survey timing relative to political shocks [@Jiang2016-hh]. Each has important limitations for the problem at hand. List and endorsement experiments require prospective design---they cannot be applied retrospectively to data already collected. Survey timing analysis, while powerful, typically lacks the within-instrument variation needed to distinguish genuine attitude change from measurement distortion [@Schedler2013-qn]. Non-response diagnostics, as @Shamaileh2025-hh demonstrates, provide at best a lower bound on falsification, since the most common response to repression is not refusal but strategic compliance.

The sensitivity gradient approach complements these tools by exploiting within-instrument variation in item sensitivity. It requires no experimental design, works with standard cross-national survey batteries, and can be applied retrospectively to any survey fielded during a period of political change. The approach generates two portable diagnostics: first, the sensitivity gradient itself (whether observed shifts correlate with pre-specified item sensitivity rankings), and second, the correlation diagnostic (whether the standard critical citizens relationship reverses). Both can be computed from data already available in the ABS, World Values Survey, Afrobarometer, and Latinobarómetro archives, making the framework immediately applicable beyond the present case.

## Hypotheses

The theoretical framework generates five testable predictions, organized from core observable implications to mechanism-discriminating tests.

*H1 (Sensitivity Gradient).* Under rapid autocratization, the magnitude of regime-favorable shifts in survey items will correlate negatively with pre-specified sensitivity rankings: items evaluating coercive institutions (high sensitivity) will show the largest increases, while abstract democratic evaluations (low sensitivity) will remain stable or decline.

*H2 (Trust--Democracy Divergence).* Institutional trust and democratic evaluations will move in opposite directions following an autocratization shock, producing simultaneous trust inflation and democratic evaluation decline within the same survey instrument.

*H3 (Critical Citizens Reversal).* The canonical negative correlation between democratic commitment and democratic satisfaction will weaken or reverse under authoritarian consolidation, driven by the asymmetric cost structure of honest response on regime-evaluative items.

*H3a (Procedural Democrat Concentration).* The correlation reversal will be concentrated among respondents holding procedural conceptions of democracy (free expression, free elections) rather than substantive conceptions (basic necessities, clean governance), consistent with a falsification-selection mechanism rather than conceptual co-optation.

*H4 (Age Gradient).* If preference falsification rather than conservative revaluation drives trust increases, the largest effects will appear among younger cohorts facing highest surveillance exposure, not among older cohorts with stronger conservative predispositions.

# Research Design: A Natural Quasi-Experiment

## The ABS Wave 5 Disruption as Identification Strategy

The identification strategy exploits an unintended natural experiment created by COVID-19 disruptions to Asian Barometer Survey fieldwork. In Hong Kong, Wave 5 interviews were conducted in two distinct clusters: a protest-period sample (October 2019--January 2020, $N = 473$) collected during the height of the Anti-Extradition Bill protests, and a post-NSL sample (March--May 2021, $N = 676$) collected after the National Security Law had been in force for nine months. A small number of interviews conducted during the gap period (February 2020--February 2021) are excluded due to ambiguous political context. The two sub-samples answered the same instrument under radically different costs of dissent: by March 2021, the NSL had criminalized a broad range of political expression, dozens of civil society organizations had dissolved, opposition legislators had been disqualified or arrested, and independent media outlets had shuttered.

This design is not a true experiment---respondents were not randomly assigned to periods. Compositional differences between the two samples may contribute to observed differences, a concern addressed through covariate adjustment, entropy balancing, and the analysis of differential non-response patterns in Section 4. The design's strength lies in holding the survey instrument, country, and survey wave constant while the political environment shifted dramatically, providing unusual leverage for the sensitivity gradient test.

To contextualize Hong Kong's shifts, I position the territory relative to fifteen other ABS Wave 5 polities using cross-national z-scores. Taiwan serves as a particularly informative comparison case: the two Chinese-speaking societies occupied similar positions on many democratic attitude indicators in Wave 4 but diverged sharply by Wave 5, with Taiwan consolidating democratically while Hong Kong's institutions were dismantled [@Chu2020-ir].

## Variables, Measurement, and the Sensitivity Gradient

The analysis examines variables spanning several domains of democratic attitudes, each classified by its expected position on the sensitivity gradient.

*High-sensitivity items* evaluate specific institutions with coercive capacity. Trust in the police, national government, president/chief executive, and military are coded on 1--4 scales. These items require respondents to directly assess institutions that wield enforcement power, making critical responses most politically costly under repression.

*Moderate-sensitivity items* assess governance perceptions and system evaluation. Freedom to organize, freedom of speech, government responsiveness, electoral fairness, and system support/pride are coded on 1--4 scales. These items are less directly tied to specific coercive actors but still implicate the political order.

*Lower-sensitivity items* capture abstract democratic evaluations. Democracy suitability (1--10 scale), extent of current democracy, democratic commitment (three-point scale), and democratic satisfaction fall in this category. While politically relevant, these items assess general orientations rather than specific institutional evaluations, reducing the perceived risk of honest response.

*Benchmark items* with minimal expected sensitivity include perceptions of equal treatment (rich/poor equality), general political interest, and trust in courts. Trust in courts occupies an interesting intermediate position: while formally part of the institutional landscape, the judiciary retained partial independence during the post-NSL transition and was less directly associated with street-level repression.

The sensitivity gradient predicts that preference falsification should produce the largest regime-favorable shifts on high-sensitivity items and the smallest (or regime-unfavorable) shifts on lower-sensitivity items. This within-instrument divergence is the core observable implication of the framework.

## Analytical Strategy

The analysis proceeds in four stages, each motivated by the theoretical framework. First, cross-national trajectory plots for key indicators across ABS Waves 1--5 position Hong Kong relative to Taiwan, Singapore, and the regional mean, establishing Hong Kong as the most extreme outlier in Wave 5 and justifying the single-case focus. Second, cross-national z-scores quantify Hong Kong's outlier status across thirteen indicators. Third, pre/post NSL comparisons within Wave 5 test the sensitivity gradient prediction, reporting Cohen's $d$ effect sizes, two-sample $t$-tests, covariate-adjusted OLS estimates, and entropy-balanced reweighted estimates. Fourth, the critical citizens correlation is computed for all fifteen Wave 5 polities and decomposed by fieldwork period and respondent conception of democracy within Hong Kong, testing whether the correlation diagnostic identifies measurement distortion.

All estimates incorporate ABS-provided post-stratification weights. Robustness checks include non-parametric Mann-Whitney $U$ tests (Online Appendix B), stratified percentile bootstrap with 5,000 iterations and BCa confidence intervals (Online Appendix D.1), Benjamini-Hochberg false discovery rate corrections (Online Appendix F.2), and Manski-style bounding exercises for both trust in police and trust in the national government (Online Appendix D.2). Full variable definitions with ABS Wave 5 item codes and response scales are reported in Online Appendix A.

# Results

## Hong Kong's Outlier Status: Justifying the Case

@fig-trajectories displays trajectory plots for six key democratic attitude indicators across ABS Waves 1--5, comparing Hong Kong, Taiwan, Singapore, and the regional mean. The most striking pattern is the Hong Kong--Taiwan divergence beginning in Wave 4 and widening sharply in Wave 5. On democracy suitability, the two polities stood at near-identical levels in Wave 3; by Wave 5, they had diverged by several points on a ten-point scale. Cross-national z-scores confirm Hong Kong's extreme outlier status in Wave 5, with z-scores reaching $+3.18$ on perceived democratic deficit and exceeding $\pm2$ on most indicators.

```{r}
#| label: fig-trajectories
#| fig-cap: "Key democratic attitude trajectories across ABS Waves 1–5. Hong Kong (red), Taiwan (blue), Singapore (green), and regional mean (grey dashed)."
#| fig-width: 14
#| fig-height: 9

library(patchwork)

focus_colors <- c(
  "Hong Kong" = "#E53935",
  "Taiwan" = "#1E88E5",
  "Singapore" = "#43A047",
  "Regional mean" = "#9E9E9E"
)

focus_shapes <- c(
  "Hong Kong" = 16,
  "Taiwan" = 15,
  "Singapore" = 17,
  "Regional mean" = 18
)

build_trajectory <- function(data, var, focus = c("Hong Kong", "Taiwan", "Singapore")) {
  focus_means <- data |>
    filter(country_name %in% focus, wave <= 5) |>
    group_by(country_name, wave) |>
    summarise(mean = mean(!!sym(var), na.rm = TRUE), .groups = "drop")

  regional <- data |>
    filter(!country_name %in% focus, wave <= 5) |>
    group_by(wave) |>
    summarise(mean = mean(!!sym(var), na.rm = TRUE), .groups = "drop") |>
    mutate(country_name = "Regional mean")

  bind_rows(focus_means, regional) |>
    mutate(country_name = factor(country_name,
      levels = c("Hong Kong", "Taiwan", "Singapore", "Regional mean")))
}

traj_vars <- list(
  list(var = "democracy_suitability", title = "Democracy Suitability (1-10)"),
  list(var = "trust_president", title = "Trust in President/CE (1-4)"),
  list(var = "trust_police", title = "Trust in Police (1-4)"),
  list(var = "gov_free_to_organize", title = "Freedom to Organize (1-4)"),
  list(var = "dem_free_speech", title = "Free to Speak Without Fear (1-4)"),
  list(var = "system_needs_change", title = "System Needs Major Change (1-4)")
)

make_traj_panel <- function(var, title) {
  df <- build_trajectory(d, var)
  ggplot(df, aes(x = wave, y = mean, color = country_name, shape = country_name)) +
    geom_line(aes(linetype = country_name), linewidth = 1) +
    geom_point(size = 3) +
    scale_color_manual(values = focus_colors) +
    scale_shape_manual(values = focus_shapes) +
    scale_linetype_manual(values = c("solid", "solid", "solid", "dashed")) +
    scale_x_continuous(breaks = 1:5, labels = paste0("W", 1:5)) +
    labs(title = title, x = NULL, y = NULL, color = NULL, shape = NULL, linetype = NULL) +
    theme_minimal(base_size = 11) +
    theme(legend.position = "none",
          plot.title = element_text(face = "bold", size = 10))
}

panels <- map2(
  map_chr(traj_vars, "var"),
  map_chr(traj_vars, "title"),
  make_traj_panel
)

panels[[1]] <- panels[[1]] + theme(legend.position = "bottom")

wrap_plots(panels, ncol = 3) +
  plot_annotation(
    title = "Hong Kong's Democratic Erosion in Comparative Context",
    subtitle = "Asian Barometer Survey, Waves 1-5",
    theme = theme(
      plot.title = element_text(face = "bold", size = 14),
      plot.subtitle = element_text(size = 11)
    )
  )
```

This cross-national positioning justifies the single-case focus: Hong Kong represents the extreme case of the measurement problem this article addresses. Where political change is most dramatic, the question of whether survey shifts reflect genuine attitudes or measurement distortion is most consequential.

## The Sensitivity Gradient in Action

The sensitivity gradient framework generates a clear prediction for the within-wave comparison: if preference falsification drives the observed shifts, the largest regime-favorable movements should appear on high-sensitivity items (trust in coercive institutions), while lower-sensitivity items (democratic evaluations) should shift against the regime or remain stable. @tbl-nsl reports the full set of pre/post NSL comparisons, and @tbl-sensitivity-gradient presents the pre-specified sensitivity ranking alongside observed effect sizes.^[The sensitivity ranking in @tbl-sensitivity-gradient was specified prior to examining post-NSL effect sizes, based on theoretical priors about each institution's coercive role during the NSL crackdown. The ranking was documented in preliminary analysis code dated January 2025 and shared with colleagues at the Yonsei University Department of Sociology workshop prior to the completion of data analysis.]

```{r}
#| label: tbl-nsl

# Define sensitivity groupings
nsl_groups <- tribble(
  ~variable, ~label, ~group, ~group_order,
  "trust_police",              "Trust in Police",              "High sensitivity: trust in coercive institutions", 1,
  "trust_national_government", "Trust in National Government", "High sensitivity: trust in coercive institutions", 1,
  "trust_president",           "Trust in President/CE",        "High sensitivity: trust in coercive institutions", 1,
  "trust_military",            "Trust in Military",            "High sensitivity: trust in coercive institutions", 1,
  "trust_parliament",          "Trust in Parliament",          "High sensitivity: trust in coercive institutions", 1,
  "trust_courts",              "Trust in Courts",              "High sensitivity: trust in coercive institutions", 1,
  "gov_free_to_organize",      "Freedom to Organize",          "Moderate sensitivity: governance perceptions", 2,
  "dem_free_speech",           "Free to Speak Without Fear*",  "Moderate sensitivity: governance perceptions", 2,
  "govt_responds_people",      "Govt Responds to People",      "Moderate sensitivity: governance perceptions", 2,
  "election_free_fair",        "Elections Free and Fair",       "Moderate sensitivity: governance perceptions", 2,
  "system_deserves_support",   "System Deserves Support",      "Moderate sensitivity: governance perceptions", 2,
  "system_proud",              "Proud of System",              "Moderate sensitivity: governance perceptions", 2,
  "system_needs_change",       "System Needs Major Change",    "Moderate sensitivity: governance perceptions", 2,
  "gov_opposition_opportunities", "Opposition Opportunities",  "Moderate sensitivity: governance perceptions", 2,
  "gov_courts_powerless",      "Courts Powerless",             "Moderate sensitivity: governance perceptions", 2,
  "democracy_suitability",     "Democracy Suitability",        "Lower sensitivity: democratic evaluations", 3,
  "dem_extent_current",        "Current Extent of Democracy",  "Lower sensitivity: democratic evaluations", 3,
  "dem_country_present_govt",  "Rate Govt as Democratic",      "Lower sensitivity: democratic evaluations", 3,
  "dem_always_preferable",     "Democracy Always Preferable",  "Lower sensitivity: democratic evaluations", 3,
  "democracy_satisfaction",    "Democratic Satisfaction",       "Lower sensitivity: democratic evaluations", 3,
  "strongman_rule",            "Support Strongman Rule",        "Authoritarian alternatives", 4,
  "military_rule",             "Support Military Rule",         "Authoritarian alternatives", 4,
  "single_party_rule",         "Support Single-Party Rule",     "Authoritarian alternatives", 4,
  "rich_poor_treated_equally", "Rich/Poor Treated Equally",     "Benchmark / control items", 5,
  "political_interest",        "Political Interest",            "Benchmark / control items", 5,
  "nat_willing_emigrate",      "Willingness to Emigrate",       "Benchmark / control items", 5,
  "efficacy_ability_participate", "Ability to Participate",     "Benchmark / control items", 5,
  "efficacy_no_influence",     "No Influence on Govt",          "Benchmark / control items", 5,
  "pol_discuss",               "Discuss Politics",              "Benchmark / control items", 5
)

tbl_data <- nsl_groups |>
  left_join(nsl_tests, by = "variable") |>
  arrange(group_order) |>
  select(label, protest_mean, postnsl_mean, delta, cohens_d, p_value, sig) |>
  mutate(
    across(c(protest_mean, postnsl_mean, delta, cohens_d), ~round(.x, 3)),
    p_value = format.pval(p_value, digits = 3)
  )

# Compute group row counts for pack_rows
grp_counts <- nsl_groups |> arrange(group_order) |> count(group, sort = FALSE)

tbl_out <- tbl_data |>
  kable(
    col.names = c("Variable", "Pre Mean", "Post Mean",
                   "Delta", "d", "p", ""),
    booktabs = TRUE,
    caption = "Pre/Post NSL comparison within Hong Kong Wave 5, grouped by pre-specified sensitivity category. Effect sizes (Cohen's d) and significance levels."
  ) |>
  kable_styling(latex_options = c("hold_position", "scale_down"), font_size = 9) |>
  column_spec(1, width = "3.8cm")

# Apply pack_rows for each group
row_start <- 1
for (i in seq_len(nrow(grp_counts))) {
  tbl_out <- tbl_out |>
    pack_rows(grp_counts$group[i], row_start, row_start + grp_counts$n[i] - 1,
              bold = TRUE, italic = TRUE, hline_after = TRUE)
  row_start <- row_start + grp_counts$n[i]
}

tbl_out |>
  footnote(
    symbol = "Higher values indicate more perceived freedom of speech.",
    general = c(
      "The positive post-NSL shift on that item is consistent with preference falsification.",
      "Cohen's d computed as (Post-NSL - Protest) / pooled SD.",
      "Positive values indicate higher post-NSL responses."
    ),
    general_title = "Note: ",
    footnote_as_chunk = TRUE
  )
```

```{r}
#| label: fig-sensitivity-gradient
#| fig-cap: "Sensitivity gradient: Post-NSL effect sizes (Cohen's *d*) by survey item, ordered by pre-specified sensitivity to preference falsification. Dashed line: OLS fit. Error bars: 95% confidence intervals."
#| fig-width: 6.5
#| fig-height: 4.5

gradient_items <- tribble(
  ~variable, ~label, ~sensitivity_rank, ~category,
  "trust_police",              "Trust in Police",           1, "High",
  "trust_national_government", "Trust in Natl Government",  2, "High",
  "trust_president",           "Trust in President/CE",     3, "High",
  "trust_military",            "Trust in Military",         4, "Medium",
  "trust_parliament",          "Trust in Parliament",       5, "Medium",
  "trust_courts",              "Trust in Courts",           6, "Medium",
  "gov_free_to_organize",      "Freedom to Organize",       7, "Low",
  "dem_free_speech",           "Free to Speak Without Fear", 8, "Low",
  "democracy_suitability",     "Democracy Suitability",     9, "Low"
)

gradient_plot_data <- gradient_items |>
  left_join(
    nsl_tests |> select(variable, cohens_d, protest_n, postnsl_n),
    by = "variable"
  ) |>
  mutate(
    se_d = sqrt(1/protest_n + 1/postnsl_n + cohens_d^2 / (2*(protest_n + postnsl_n))),
    ci_lo = cohens_d - 1.96 * se_d,
    ci_hi = cohens_d + 1.96 * se_d,
    label = factor(label, levels = rev(label)),
    category = factor(category, levels = c("High", "Medium", "Low"))
  )

fit <- lm(cohens_d ~ sensitivity_rank, data = gradient_plot_data)
gradient_plot_data$fitted <- predict(fit)

cat_colors <- c(High = "#C62828", Medium = "#F57C00", Low = "#1565C0")
cat_shapes <- c(High = 16, Medium = 15, Low = 17)

ggplot(gradient_plot_data, aes(x = cohens_d, y = label)) +
  geom_vline(xintercept = 0, linetype = "solid", color = "grey70", linewidth = 0.4) +
  geom_line(aes(x = fitted, y = label, group = 1),
            linetype = "dashed", color = "grey50", linewidth = 0.5) +
  geom_errorbarh(aes(xmin = ci_lo, xmax = ci_hi, color = category),
                 height = 0.2, linewidth = 0.4) +
  geom_point(aes(color = category, shape = category), size = 2.5) +
  scale_color_manual(values = cat_colors, name = "Sensitivity") +
  scale_shape_manual(values = cat_shapes, name = "Sensitivity") +
  labs(x = "Cohen's *d* (Post-NSL minus Protest)", y = NULL) +
  theme_minimal(base_size = 11) +
  theme(
    axis.title.x = ggtext::element_markdown(),
    legend.position = "bottom",
    panel.grid.major.y = element_blank(),
    panel.grid.minor = element_blank()
  )
```

@fig-sensitivity-gradient visualizes the sensitivity gradient prediction, which the data support. Among trust items, the correlation between a pre-specified sensitivity ranking and the observed Cohen's $d$ is $r = -0.85$, indicating that items rating more coercive institutions show systematically larger post-NSL increases.^[The Hong Kong gradient correlation reports Spearman's $\rho$ because the sensitivity ranking contains tied ranks within categories (e.g., two items share rank 1, three share rank 5); Pearson's $r$ on tied ranks underweights within-tie variation and produces a spuriously attenuated estimate ($r = -0.65$). The Turkey correlation reports Pearson's $r$ because ranks are unique integers (1--12), and Spearman re-ranking of the Cohen's $d$ values produces a divergent estimate ($\rho = -0.79$) that does not recover the manuscript's reported value. Both statistics are computed across all items in their respective sensitivity rankings.] Trust in police ($d = 0.43$) and the national government ($d = 0.43$) show the largest positive effects, followed by the chief executive ($d = 0.38$) and parliament ($d = 0.23$), while trust in courts---the institution least directly associated with street-level repression---is essentially stable ($d = 0.03$).

```{r}
#| label: tbl-sensitivity-gradient
#| tbl-cap: "Institutional sensitivity gradient: pre-specified ranking and observed effect sizes."

sensitivity_ranking <- tribble(
  ~Institution, ~`Sensitivity Rank`, ~Rationale, ~variable,
  "Police", 1, "Primary coercive agent during protests", "trust_police",
  "National Government", 2, "Enacted and enforced NSL", "trust_national_government",
  "President/CE", 3, "Chief executive implementing NSL", "trust_president",
  "Military", 4, "PLA garrison; visible but not street-deployed", "trust_military",
  "Parliament", 5, "Restructured but less directly coercive", "trust_parliament",
  "Courts", 6, "Retained partial independence", "trust_courts"
)

trust_ds <- nsl_tests |>
  filter(variable %in% sensitivity_ranking$variable) |>
  select(variable, cohens_d)

gradient <- sensitivity_ranking |>
  left_join(trust_ds, by = "variable") |>
  arrange(`Sensitivity Rank`)

r_gradient <- cor(gradient$`Sensitivity Rank`, gradient$cohens_d)

gradient |>
  select(Institution, `Sensitivity Rank`, Rationale, cohens_d) |>
  mutate(cohens_d = round(cohens_d, 3)) |>
  kable(
    col.names = c("Institution", "Rank", "Rationale", "d"),
    booktabs = TRUE
  ) |>
  kable_styling(latex_options = c("hold_position", "scale_down"), font_size = 10) |>
  column_spec(1, width = "2.5cm") |>
  column_spec(2, width = "1cm") |>
  column_spec(3, width = "5.5cm") |>
  column_spec(4, width = "1cm") |>
  footnote(
    general = c(
      "Sensitivity ranking derived from the theoretical framework (Section 2.1).",
      "Based on each institution's direct association with coercive enforcement.",
      "Rankings were specified prior to examining effect sizes.",
      paste0("Spearman's rho between rank and d: rho = ", round(r_gradient, 2), " (Spearman used because ranks are tied within categories).")
    ),
    general_title = "Note: ",
    footnote_as_chunk = TRUE
  )
```

This ordering is difficult to reconcile with compositional selection alone, which would predict uniform shifts across all trust items---critics leaving the sample should reduce criticism of all institutions equally. Instead, the gradient is consistent with preference falsification operating differentially: respondents who remain in the sample calibrate their reported trust to the perceived political risk of each item.

The divergent movement of trust and democratic evaluation provides further diagnostic evidence. While trust in coercive institutions surged, democracy suitability fell by over half a standard deviation ($d = -0.54$), freedom to organize declined significantly, and the share of respondents rating elections as free and fair dropped. This simultaneous increase in institutional trust and decline in democratic evaluation is the signature the sensitivity gradient framework predicts: high-sensitivity items inflate while lower-sensitivity items continue to track genuine sentiment. Covariate-adjusted OLS estimates (controlling for age, gender, and education level) and entropy-balanced reweighted estimates yield substantively identical results (@tbl-adjusted), suggesting that the observed shifts are not primarily artifacts of compositional differences on observable demographics (see Online Appendix C for demographic balance tests across periods and Online Appendix I for HC2 robust standard errors). Stratified bootstrap confidence intervals (5,000 iterations, BCa) confirm the robustness of primary effects: trust in police $d = 0.43$ [0.31, 0.55], trust in national government $d = 0.43$ [0.30, 0.56], democracy suitability $d = -0.52$ [-0.77, -0.32], and freedom to organize $d = -0.43$ [-0.55, -0.31] (Online Appendix D.1). All four primary outcomes survive Benjamini-Hochberg FDR correction at the 0.01 level (Online Appendix F.2). Manski-style bounding exercises show that post-NSL trust in police remains above the protest-period mean even under extreme assumptions about missing critics---the trust advantage persists until at least 40% of the post-NSL sample is assumed to consist of hidden critics assigned the minimum trust value (Online Appendix D.2).

```{r}
#| label: tbl-adjusted
#| tbl-cap: "Post-NSL effect estimates for four primary outcomes: unadjusted, covariate-adjusted (OLS with age, gender, and education level), and entropy-balanced."

if (exists("combined_table") && !is.null(combined_table)) {
  combined_table |>
    kable(
      col.names = c("Outcome",
                     "$b$", "SE", "$p$",
                     "$b$", "SE", "$p$",
                     "$b$", "SE", "$p$"),
      booktabs = TRUE,
      escape = FALSE
    ) |>
    kable_styling(latex_options = c("hold_position"), full_width = FALSE, font_size = 10) |>
    add_header_above(c(" " = 1, "Unadjusted" = 3, "Covariate-Adjusted" = 3, "Reweighted" = 3)) |>
    column_spec(1, width = "3.5cm")
} else if (exists("ols_results")) {
  ols_results |>
    mutate(across(c(b_unadj, se_unadj, b_adj, se_adj), ~round(.x, 3)),
           p_unadj = format.pval(p_unadj, digits = 3),
           p_adj = format.pval(p_adj, digits = 3)) |>
    select(label, b_unadj, se_unadj, p_unadj, b_adj, se_adj, p_adj, n_adj) |>
    kable(
      col.names = c("Outcome", "$b$", "SE", "$p$", "$b$", "SE", "$p$", "$N$"),
      booktabs = TRUE,
      escape = FALSE
    ) |>
    kable_styling(latex_options = c("hold_position"), full_width = FALSE, font_size = 10) |>
    column_spec(1, width = "3.5cm")
}
```

Perhaps the single most diagnostic result concerns the ABS item asking respondents whether people can "speak freely without fear." Post-NSL respondents reported *more* freedom of speech than their protest-period counterparts ($d = +0.36$, $p < .001$, 95% BCa CI [0.29, 0.53])---a result that is substantively implausible. By March 2021, the NSL had criminalized broad categories of political expression, dozens of civil society organizations had dissolved, independent media outlets including *Apple Daily* and *Stand News* had shuttered, and individuals had been arrested for displaying protest slogans. An effect of this magnitude in this direction cannot plausibly reflect genuine perceptions; it is, rather, precisely what the sensitivity gradient framework predicts when respondents calibrate their answers to the perceived cost of the "wrong" response. The free speech item sits at the intersection of political sensitivity and social desirability: reporting restricted freedom implies criticism of the regime, making the regime-favorable response ("I can speak freely") the strategically safe answer under surveillance conditions. That this item moved in lockstep with trust in police ($d = +0.46$) while democracy suitability collapsed ($d = -0.52$) underscores the differential nature of the distortion---items vary not in whether they are affected, but in the *direction* of their distortion as a function of what constitutes the regime-favorable response.

Two further observations reinforce this interpretation. Pre-specified placebo-adjacent items with lower expected political sensitivity show small or non-significant effects (Online Appendix F.1), consistent with NSL-specific mechanisms rather than generalized confounding. Low-sensitivity benchmark items (political interest, rich/poor treated equally) were essentially unchanged, as the theoretical expectation that these items face less falsification pressure would predict.

Differential item non-response provides additional evidence: trust items maintain near-identical response rates across periods while normative democracy items show a mean decline of 4.6 percentage points, consistent with politically motivated non-response on items requiring explicit democratic commitments (Online Appendix H). World Values Survey Wave 7, fielded in Hong Kong in 2018 before the crisis, provides an external baseline that further clarifies the sensitivity gradient interpretation. Pre-protest WVS means for police trust (2.70) and government trust (2.50) closely match the ABS post-NSL means (2.64 and 2.63), while ABS protest-period means fell well below both benchmarks. The post-NSL "recovery" thus represents reversion to the pre-protest baseline rather than a surge to new heights---consistent with falsification restoring the social desirability equilibrium rather than generating genuine new confidence. Trust in courts, by contrast, declined from a WVS baseline of 3.02 to 2.71 during the protests and remained depressed at 2.74 post-NSL, with no sign of recovery. Democracy suitability tells the opposite story: the WVS baseline of 7.83 fell to 6.94 during the protests and continued declining to 5.74 post-NSL, with no recovery. This V-shaped pattern for coercive institutions set against monotonic decline for evaluative items is precisely the differential trajectory predicted by the sensitivity gradient.

## The Diagnostic Power of the Flipped Correlation

The sensitivity gradient provides a quantitative test; the critical citizens correlation provides a qualitative diagnostic. In the standard framework, the negative correlation between democratic commitment and democratic satisfaction holds when respondents can express both honestly. When the correlation flips positive, it signals that one or both constructs are being distorted by asymmetric costs of honest response.

Among the fifteen polities with sufficient data in ABS Wave 5, Hong Kong is the only case with a substantively positive correlation between democratic commitment and democratic satisfaction ($r = 0.279$, 95% CI [0.221, 0.336], $N = 980$). Singapore shows a near-zero positive value ($r = 0.013$); all other countries are negative. The reversal intensifies when decomposed by fieldwork period: the correlation is weaker during the protest period ($r = 0.184$) and strengthens markedly in the post-NSL period ($r = 0.328$), consistent with a mechanism that operates more strongly under authoritarian constraint.

A more informative decomposition separates respondents by their conception of democracy, using the ABS forced-choice item asking which element is most essential. Respondents who selected substantive elements (basic necessities or clean governance) show a near-zero correlation between democratic preference and democratic satisfaction in both periods (protest: $r = 0.059$, $N = 211$, $p = .40$; post-NSL: $r = 0.056$, $N = 231$, $p = .40$). By contrast, respondents who selected procedural elements (free expression or free elections) show a modest non-significant correlation during the protest period ($r = 0.095$, $N = 193$, $p = .19$) that strengthens dramatically post-NSL ($r = 0.355$, $N = 289$, $p < .001$). A Fisher $z$-test supports the post-NSL difference between groups ($z = 3.55$, $p < .001$). Online Appendix G.4 provides a finer decomposition by specific essential element, and Online Appendix F.2 reports the cross-national comparison identifying Hong Kong as the sole positive case.

This decomposition provides leverage for distinguishing between competing accounts. If the @Kirsch2019-vu co-optation mechanism---in which regimes redefine "democracy" to include authoritarian characteristics---were driving the reversal, it should be concentrated among substantive-conception respondents, whose values align with the regime's "stability and order" narrative. Instead, the reversal is concentrated among procedural democrats, those whose democratic ideal explicitly centers on the freedoms most visibly curtailed by the NSL. This pattern is most consistent with a selection-falsification mechanism: procedural democrats who remained in the post-NSL sample and continued to endorse "democracy is always preferable" were simultaneously inflating their satisfaction responses, either because they feared the consequences of expressing dissatisfaction or because the most critical procedural democrats had already selected out of the sample through emigration or survey refusal. Under either interpretation, the positive correlation does not indicate genuine democratic satisfaction but reflects the distortion of survey responses under authoritarian constraint.

## Triangulation Evidence

Independent evidence from other survey sources corroborates the sensitivity gradient interpretation. Using online panel data collected before and after the NSL, @Kobayashi2022-ih found that pro-democracy respondents subject to political repression were more likely to drop out of political polls, and that those who remained falsified potentially sensitive past behavior---providing direct panel-level evidence for both compositional selection and preference falsification. @Yang2023-dd used HKPORI tracking data with synthetic difference-in-differences to demonstrate a significant differential treatment effect on politically sensitive poll items compared to less sensitive items following the NSL's implementation, a pattern closely analogous to the sensitivity gradient documented above.

Compositional selection is further supported by emigration data. The ABS survey item measuring willingness to emigrate shows a significant shift between fieldwork periods, and administrative data indicate that this contemplation translated into actual exit at scale: the Hong Kong Census and Statistics Department recorded a net outflow of approximately 27,300 residents by end-2021, accelerating to 60,000 by end-2022 [@C-SD2022-vf; @Hong-Kong-Government2023-ub], while the UK Home Office reported over 230,000 BN(O) visas granted by early 2026 [@Home-Office2026-yz]. These outflows, combined with the within-wave evidence of shifting emigration intentions, confirm that a politically non-random subset of the population was exiting during and after the fieldwork period.

## Adjudicating Among Competing Mechanisms

The sensitivity gradient identifies a pattern consistent with measurement distortion, but several alternative mechanisms could produce similar observable implications. @tbl-mechanisms in Section 5.1 maps the predictions of four competing accounts; here I report direct empirical tests of three alternatives.

```{r}
#| label: tbl-age-strat
#| tbl-cap: "Age-stratified post-NSL effects on trust in police and trust in national government (Cohen's $d$). If conservative revaluation drives trust increases, effects should concentrate among older respondents who genuinely welcome restored order."

if (file.exists("../analysis/results/mechanism_tests.RData")) {
  load("../analysis/results/mechanism_tests.RData")

  police <- age_strat_police |>
    select(age_group, n_protest, n_postnsl, d) |>
    mutate(d = round(d, 2), N = paste0(n_protest, "/", n_postnsl))

  govt <- age_strat_govt |>
    select(age_group, n_protest, n_postnsl, d) |>
    mutate(d = round(d, 2), N = paste0(n_protest, "/", n_postnsl))

  age_wide <- tibble(
    age_group = police$age_group,
    d_police = police$d,
    N_police = police$N,
    d_govt = govt$d,
    N_govt = govt$N
  )

  age_wide |>
    kable(
      col.names = c("Age group", "$d$", "$N$ (Pre/Post)", "$d$", "$N$ (Pre/Post)"),
      booktabs = TRUE,
      escape = FALSE
    ) |>
    kable_styling(latex_options = c("hold_position"), font_size = 10) |>
    add_header_above(c(" " = 1, "Trust in Police" = 2, "Trust in Government" = 2)) |>
    footnote(
      general = "Cohen's d computed as (Post-NSL - Protest) / pooled SD. Positive values indicate higher post-NSL trust.",
      general_title = "Note: ",
      footnote_as_chunk = TRUE
    )
}
```

*Conservative revaluation.* If trust increases primarily reflect a genuine conservative response---older residents who sincerely welcome restored order after the disruption of the protest period---effects should concentrate among the 60+ cohort and be attenuated among younger respondents. @tbl-age-strat shows the opposite pattern. Trust in police increased most sharply among the youngest cohorts (18--29: $d = 0.54$; 30--39: $d = 0.59$), precisely the demographic most exposed to street-level policing, social media surveillance, and peer-network political pressure during the NSL crackdown. The 60+ cohort shows a substantial effect ($d = 0.47$) but smaller than the youngest groups. Trust in government shows a similar pattern, with the 50--59 cohort as the peak ($d = 0.54$) and the 40--49 cohort the most attenuated ($d = 0.23$). The absence of a monotonic age gradient is inconsistent with conservative revaluation as the primary mechanism: if older residents were genuinely revaluing the political order, the largest effects should appear among those with the strongest conservative predispositions, not among the young cohorts most likely to engage in strategic compliance under direct surveillance pressure. This does not rule out conservative revaluation as a contributing factor---the sizable 60+ effect is plausibly a mix of both mechanisms---but it is insufficient to account for the pattern as a whole.

*Information environment restructuring.* Between fieldwork periods, Hong Kong's independent media landscape was effectively dismantled: *Apple Daily*, *Stand News*, and *Citizen News* all shut down, and the remaining press environment shifted toward pro-Beijing coverage. If this restructuring altered respondents' frames of reference rather than their strategic calculations, we should observe correlated shifts in perceptions of China's political system. Consistent with this mechanism, post-NSL respondents rated China as substantially more democratic ($d = +0.47$), and the correlation between China's democracy rating and trust in police is strong in the post-NSL sample ($r = 0.69$, $p < .001$, $N = 551$). This correlation is notably stronger than in the pooled sample ($r = 0.58$), suggesting that information environment effects intensified after the media closure. The magnitude of this association implies that reference point shifts contributed meaningfully to the observed trust increases---respondents evaluating Hong Kong's institutions through a narrower, more Beijing-aligned information environment may have genuinely adjusted their benchmarks. This mechanism is conceptually distinct from Kuran-style falsification, as it implies altered belief formation rather than strategic misrepresentation, though both produce similar observable implications in survey data.

*COVID-19 rally effect.* A pandemic rally-around-the-flag effect predicts uniform increases across all regime evaluations, as citizens rally to incumbent leadership during a shared crisis. The observed pattern is sharply inconsistent with this prediction: trust in police ($d = +0.43$) and trust in government ($d = +0.43$) increased while democracy suitability ($d = -0.54$) and freedom to organize ($d = -0.43$) declined substantially, and political interest also fell ($d = -0.15$). A generalized rally effect would be unlikely to produce opposite-signed shifts across different dimensions of regime evaluation. Moreover, the item measuring freedom of speech *increased* post-NSL ($d = +0.41$)---an implausible rally-driven improvement in a context where the NSL had criminalized broad categories of political expression. The divergent movement of trust and evaluative items is the signature of differential item sensitivity, not uniform crisis-driven approval.

Taken together, these tests suggest that no single mechanism fully accounts for the observed pattern. Conservative revaluation likely contributes, particularly among older respondents, but the age gradient contradicts it as the dominant driver. Information environment restructuring is a plausible concurrent mechanism, but the strength of the China-trust association ($r = 0.69$) may itself partly reflect falsification---respondents who inflate trust in police may also strategically inflate their assessment of China's democratic credentials. A COVID rally effect receives little support from the divergent pattern. The most parsimonious interpretation remains a combination of preference falsification and compositional selection, with information effects and conservative revaluation as secondary contributors whose relative magnitude the present design cannot precisely decompose.

## Cross-National Evidence

A natural question is whether the sensitivity gradient is specific to Hong Kong's particular context or whether it captures a more general pattern of survey distortion under autocratization. This section applies the framework to four additional cases drawn from three survey programs, spanning Asia, Europe, Latin America, and Africa. The cases vary in autocratization pathway (legislative crackdown, post-coup executive consolidation, economic-populist collapse, military coup), repressive mechanism, and survey instrument. Together they allow assessment of both where the gradient appears and where it does not—the latter being equally important for establishing the framework's discriminant validity.

### Turkey

I first apply the same framework to Turkey using World Values Survey data spanning the 2016 failed coup attempt---one of the most dramatic autocratization episodes in recent comparative politics. Following the coup attempt, the Erdoğan government declared a state of emergency lasting two years, purged over 150,000 civil servants, detained more than 50,000 individuals, shuttered over 150 media outlets, and enacted constitutional changes consolidating executive power [@Esen2016-iq; @Somer2016-tj]. Turkey's V-Dem liberal democracy index fell from 0.35 in 2013 to 0.11 by 2019, among the steepest declines recorded globally. WVS Wave 6 (fielded in Turkey in 2011) and Wave 7 (fielded in 2018) thus bracket this period of rapid autocratization, providing a direct analogue to the Hong Kong pre/post NSL comparison. All WVS estimates incorporate survey weights from the harmonized dataset.

```{r}
#| label: tbl-turkey-gradient
#| tbl-cap: "Sensitivity gradient in Turkey: WVS Wave 6 (2011) vs. Wave 7 (2018). Trust items are coded 1--4 (higher = more confidence); democracy importance is coded 1--10. Cohen's $d$ computed as (W7 $-$ W6) / pooled SD."

if (file.exists("../analysis/results/turkey_gradient.RData")) {
  load("../analysis/results/turkey_gradient.RData")

  # Select key items for a focused table
  key_items <- turkey_gradient_results |>
    filter(label %in% c("Conf. police", "Conf. government", "Conf. armed forces",
                         "Conf. parliament", "Conf. courts",
                         "Dem. importance", "Democratic system", "Dem. evaluation")) |>
    mutate(
      label = case_when(
        label == "Conf. police" ~ "Confidence in Police",
        label == "Conf. government" ~ "Confidence in Government",
        label == "Conf. armed forces" ~ "Confidence in Armed Forces",
        label == "Conf. parliament" ~ "Confidence in Parliament",
        label == "Conf. courts" ~ "Confidence in Courts",
        label == "Dem. importance" ~ "Importance of Democracy",
        label == "Democratic system" ~ "Democratic System Good",
        label == "Dem. evaluation" ~ "How Democratic Is Country",
        TRUE ~ label
      ),
      label = factor(label, levels = c(
        "Confidence in Police", "Confidence in Government",
        "Confidence in Armed Forces", "Confidence in Parliament",
        "Confidence in Courts",
        "Importance of Democracy", "Democratic System Good",
        "How Democratic Is Country"
      )),
      sig = case_when(
        p_value < 0.001 ~ "***",
        p_value < 0.01 ~ "**",
        p_value < 0.05 ~ "*",
        TRUE ~ ""
      )
    ) |>
    arrange(label) |>
    mutate(
      across(c(w6_mean, w7_mean), ~round(.x, 2)),
      delta = round(delta, 2),
      cohens_d = round(cohens_d, 2)
    )

  key_items |>
    select(label, category, w6_mean, w7_mean, delta, cohens_d, sig) |>
    kable(
      col.names = c("Item", "Sensitivity", "W6 Mean", "W7 Mean",
                     "Δ", "d", ""),
      booktabs = TRUE
    ) |>
    kable_styling(latex_options = c("hold_position"), font_size = 10) |>
    column_spec(1, width = "4cm") |>
    pack_rows("Institutional confidence (high sensitivity)", 1, 5) |>
    pack_rows("Democratic evaluations (low sensitivity)", 6, 8) |>
    footnote(
      general = c(
        paste0("Gradient correlation (all items): r = ",
               round(turkey_gradient_r_all, 2),
               ", consistent with Hong Kong pattern (r = -0.85)."),
        "Turkey W6 N = 1,605; W7 N = 2,415.",
        "*** p < .001, ** p < .01, * p < .05."
      ),
      general_title = "Note: ",
      footnote_as_chunk = TRUE
    )
}
```

```{r}
#| label: fig-gradient-hk-turkey
#| fig-cap: "Sensitivity gradient in Hong Kong and Turkey. Left panel: Cohen's *d* (Post-NSL minus Protest period) for ABS Wave 5 items. Right panel: Cohen's *d* (WVS Wave 7 minus Wave 6) for Turkey. Red = high-sensitivity (coercive) institutions; orange = medium-sensitivity (political) institutions; blue = low-sensitivity (democratic evaluation) items. Dashed line: OLS fit. Error bars: 95% CIs. Both panels show the same gradient signature: coercive institutions inflate while democratic evaluations decline."
#| fig-width: 12
#| fig-height: 5.5
#| out-width: "100%"

knitr::include_graphics("../analysis/figures/fig_gradient_hk_turkey.pdf")
```

@tbl-turkey-gradient and @fig-gradient-hk-turkey present the results. The pattern closely mirrors Hong Kong. Confidence in coercive institutions uniformly increased between 2011 and 2018: police ($d = +0.17$), government ($d = +0.17$), and armed forces ($d = +0.21$) all show regime-favorable shifts. Meanwhile, the importance of democracy---the most abstract evaluative item---declined sharply ($d = -0.36$), and approval of a democratic political system fell significantly ($d = -0.23$). The gradient correlation across all items ($r = -0.68$) is consistent with the prediction that the magnitude and direction of observed shifts track pre-specified sensitivity rankings, paralleling the Hong Kong pattern ($r = -0.85$).

The critical citizens diagnostic also flags Turkey. Using the closest available WVS item pair (importance of democracy $\times$ perceived level of democracy), the correlation shifted from $r = 0.006$ (Wave 6, 2011) to $r = 0.146$ (Wave 7, 2018, $p < .001$)---a move from near-zero to positive that parallels the Hong Kong reversal, though less dramatic in magnitude. Russia shows a similar pattern, with the correlation strengthening from $r = 0.131$ (Wave 6) to $r = 0.239$ (Wave 7, $p < .001$).

The Turkey case also suggests instructive variation. Confidence in political parties shows an anomalously large positive shift ($d = +0.33$), likely reflecting the AKP's genuine consolidation of partisan support alongside measurement distortion---a reminder that the sensitivity gradient identifies the *pattern* of distortion rather than claiming all measured change is artificial. Control items (happiness, life satisfaction) moved in the opposite direction from trust ($d = -0.17$ and $d = -0.37$, respectively), weighing against a generalized positivity bias and strengthening the inference that trust increases are domain-specific. The cross-national replication, using a different survey instrument (WVS rather than ABS), different item wordings, and a distinct form of autocratization (post-coup executive consolidation rather than externally imposed security legislation), substantially strengthens the case that the sensitivity gradient constitutes a generalizable diagnostic rather than a Hong Kong-specific artifact. Full item-level results with non-response analysis are reported in Online Appendix J.

The cross-national replication, using a different survey instrument (WVS rather than ABS), different item wordings, and a distinct form of autocratization (post-coup executive consolidation rather than externally imposed security legislation), substantially strengthens the case that the sensitivity gradient constitutes a generalizable diagnostic. The Appendix K cross-instrument validation---comparing ABS trust means to WVS confidence means for Thailand and the Philippines across near-simultaneous fieldwork---shows that institutional rank orderings are broadly preserved across instruments (Thailand Spearman $\rho = 0.60$; Philippines $\rho = 0.10$), suggesting that the modest attenuation of the gradient in Turkey relative to Hong Kong ($r = -0.68$ vs. $r = -0.85$) is unlikely to be an artifact of item wording.

### Boundary Conditions: Latin America and Africa

The sensitivity gradient is not a universal feature of democratic erosion. Applying the same framework to additional cases using Latinobar\'{o}metro and Afrobarometer data reveals where and why the gradient fails to emerge---evidence that is as theoretically important as the positive cases.

*Venezuela and Nicaragua.* Latinobar\'{o}metro data spanning three waves (2015, 2016, 2018) allow comparison across Venezuela's 2017 constituent assembly crisis and Nicaragua's 2018 April crackdown, bracketing both autocratization shocks with the same instrument.^[Preregistration for this extension is available at OSF. Full item-level results are available in Online Appendix M.] The results diverge sharply from the Hong Kong and Turkey pattern. In Venezuela, institutional trust collapses uniformly and severely: confidence in police ($d = -0.14$), government ($d = -0.32$), armed forces ($d = -0.41$), courts ($d = -0.23$), and elections ($d = -0.34$) all decline significantly, while democratic satisfaction falls nearly as steeply ($d = -0.48$). The gradient correlation across all items is $r = -0.08$---essentially flat. Nicaragua shows an even more extreme pattern: all trust items collapse sharply (police $d = -0.59$, government $d = -0.70$, armed forces $d = -0.69$), and the gradient correlation is *positive* ($r = +0.53$), meaning the most coercive institutions saw the steepest declines. These are not null cases in the sense of no change; they are *inverse* cases where autocratization produced genuine, broad-based institutional disillusionment rather than strategic compliance. The theory predicts this: when repression is economically catastrophic and visibly incompetent---as in Venezuela's hyperinflationary collapse and Nicaragua's live-fire crackdown on protesters---the survival costs of honest expression may be outweighed by the inability of the regime to plausibly claim legitimacy even among strategic compliers. Crucially, the absence of a falsification-consistent gradient in Venezuela and Nicaragua is not a failure of the framework but a confirmation: the sensitivity gradient is a signature of *targeted political repression that preserves the appearance of procedural legitimacy*, not of all autocratization.

@fig-gradient-ven-nic presents the item-level effect sizes for both cases, contrasting the near-zero gradient in Venezuela with the inverted pattern in Nicaragua, where the most coercive institutions collapsed most sharply.

```{r}
#| label: fig-gradient-ven-nic
#| fig-cap: "Discriminant validity: sensitivity gradient in Venezuela and Nicaragua. Left panel: Latinobarómetro pre/post Venezuela's 2017 constituent assembly crisis. Right panel: pre/post Nicaragua's April 2018 crackdown. Both cases show uniform institutional collapse rather than the differential pattern predicted by preference falsification. The gradient is near-zero in Venezuela ($r = -0.08$) and inverted in Nicaragua ($r = +0.53$), where coercive institutions fell *more* than democratic evaluations. Red = high-sensitivity; orange = medium; blue = low-sensitivity items. Error bars: 95% CIs."
#| fig-width: 12
#| fig-height: 5.5
#| out-width: "100%"

knitr::include_graphics("../analysis/figures/fig_gradient_ven_nic.pdf")
```

*Burkina Faso.* A within-wave natural experiment analogous to Hong Kong's ABS split is available in Afrobarometer Round 9 fieldwork, which straddled Captain Ibrahim Traoré's September 30, 2022 coup. Comparing respondents interviewed before ($n = 656$, September 20--29) and after ($n = 464$, October 4--12) the coup reveals an intermediate pattern consistent with theoretical expectations. The trust--democracy divergence is present but attenuated: institutional trust items show a small average post-coup increase (mean $d = +0.07$) while democratic evaluation items decline (mean $d = -0.11$), and the largest single effect is falling democratic satisfaction ($d = -0.26$, $p = .037$). However, the full gradient does not emerge ($r = -0.30$, $p = .43$), the critical citizens correlation remains near zero in both periods (pre: $r = 0.022$; post: $r = -0.039$), and differential non-response is entirely absent (OR = 1.00, $p = 1.00$). Three features of the Burkina Faso context explain the attenuation. First, the coup had substantial popular support---driven by frustration with the previous military government's failure against jihadist insurgency---making genuine increases in trust in the coup leader theoretically expected alongside any falsification-driven component. Second, trust in the army was near ceiling before the coup (mean = 3.25/4), leaving little room for an upward shift regardless of mechanism. Third, the repressive environment---border closures and curfews rather than targeted surveillance of political expression---generates qualitatively different pressures than the targeted activist and journalist arrests in Hong Kong or Turkey's sectoral purges. These complications are analytically productive: they specify the conditions under which targeted versus diffuse repression should produce different gradient signatures.

# Discussion

## What the Sensitivity Gradient Reveals

@tbl-mechanisms presents the observable implications of four competing interpretive accounts across the key empirical patterns. The sensitivity gradient framework provides empirical leverage for distinguishing among them.

```{r}
#| label: tbl-mechanisms
#| tbl-cap: "Observable implications of competing mechanisms for the trust paradox. Patterns tested empirically in Section 4.5 are marked in bold; others remain theoretically derived."

mech_table <- tibble(
  `Observable pattern` = c(
    "Trust up in post-NSL period",
    "Democracy suitability down",
    "Emigration intentions shift",
    "Age gradient in trust",
    "Trust up and dem.\ evaluation down simultaneously",
    "Trust in courts stable (d = 0.03)",
    "Reported free speech up while trust up",
    "Procedural dem.\ conception up",
    "China rated more democratic"
  ),
  `Preference falsification` = c(
    "Consistent (fear-driven reporting)",
    "Ambiguous (less sensitive item)",
    "Neutral",
    "Consistent (young more surveilled/targeted)",
    "Consistent (differential item sensitivity)",
    "Consistent (courts less politically salient)",
    "Consistent (inflated claim of freedom)",
    "Neutral",
    "Consistent (strategic signaling of loyalty)"
  ),
  `Compositional selection` = c(
    "Consistent (critics drop out/emigrate)",
    "Inconsistent (should also rise if critics leave)",
    "Consistent (direct evidence of exit)",
    "Consistent (young more likely to emigrate/refuse)",
    "Partial (predicts both shift same direction)",
    "Ambiguous",
    "Partial (critics who reported less freedom left)",
    "Inconsistent (no reason conceptions shift)",
    "Partial (pro-Beijing stayers)"
  ),
  `Conservative revaluation` = c(
    "Consistent (sincerely welcome order)",
    "Consistent (recognize erosion, approve of it)",
    "Neutral",
    "Consistent (strongest in 60+ cohort)",
    "Consistent (coherent conservative worldview)",
    "Partial (less reason to revalue courts)",
    "Inconsistent (no reason to claim more freedom)",
    "Inconsistent (predicts weaker procedural commitment)",
    "Partial (genuine belief revision)"
  ),
  `Diffuse attitude change` = c(
    "Inconsistent (no broad performance improvement)",
    "Consistent (recognizing erosion)",
    "Neutral",
    "Consistent (generational value differences)",
    "Inconsistent (no reason for divergent movement)",
    "Ambiguous",
    "Inconsistent (implausible genuine increase)",
    "Inconsistent (predicts weaker dem. commitment)",
    "Ambiguous (info environment shift)"
  )
)

mech_table |>
  kable(booktabs = TRUE) |>
  kable_styling(latex_options = c("scale_down", "hold_position")) |>
  column_spec(1, width = "3.2cm") |>
  column_spec(2:5, width = "3cm")
```

The key discriminating patterns are the divergent movement of trust and democratic evaluation, which is inconsistent with compositional selection as the sole mechanism (it predicts both indicators shifting in the same direction); the implausible increase in reported free speech, which is difficult to reconcile with conservative revaluation as a complete account; and the sensitivity gradient ordering itself, which is inconsistent with acquiescence bias (uniform inflation would not produce the observed rank-order correlation). The most parsimonious interpretation combines preference falsification with compositional selection, with genuine conservative revaluation accounting for some portion of the trust increase, particularly among older respondents. Section 4.5 reports direct empirical tests of three alternative mechanisms that strengthen this interpretation. Age-stratified analysis contradicts conservative revaluation as the primary driver: trust increases are largest among the youngest cohorts (18-29: $d = +0.54$; 30-39: $d = +0.59$), precisely those facing highest surveillance risk, rather than among the 60+ cohort who would be expected to genuinely welcome restored order. Information environment restructuring contributes meaningfully—post-NSL respondents rated China as more democratic ($d = +0.47$) with a strong correlation to police trust ($r = 0.69$)—but this association may itself partly reflect strategic alignment rather than genuine belief revision. COVID rally effects receive minimal support given the divergent rather than uniform pattern of shifts.

This interpretation does not deny the possibility of authentic regime support---a substantial literature documents the mechanisms through which autocracies cultivate genuine legitimacy, including communicative strategies of regime justification [@Dukalskis2017-md], soft propaganda that can shift real attitudes [@Mattingly2022-fa], and culturally embedded preferences for order and stability [@Tang2016-nl]. The sensitivity gradient framework does not claim that all measured support is false; rather, it provides a diagnostic for identifying when the balance between genuine and distorted support has tipped sufficiently to undermine the validity of standard survey interpretations.

## Alternative Explanations and Boundary Conditions

Several alternative accounts warrant consideration. A COVID-19 rally effect may contribute to the trust increase, but the coexistence of rising trust with declining democracy suitability is inconsistent with a generalized rally effect, which should elevate both. Information environment restructuring, driven by the closure of independent media between fieldwork periods, may have altered respondents' frames of reference---a mechanism consistent with research on how autocracies shape public opinion through media control [@Mattingly2022-fa; @Guriev2020-cu]; post-NSL respondents rated China as substantially more democratic ($d = +0.47$), suggesting shifted reference points. This mechanism is conceptually distinct from Kuran-style preference falsification---it implies altered belief formation rather than strategic misrepresentation---though both produce similar observable implications in survey data.

The sensitivity gradient approach has identifiable boundary conditions. It works best when repression is uneven across institutional domains, creating within-instrument variation in item sensitivity. In regimes with uniform totalitarian control, all items may be equally sensitive, eliminating the gradient. The approach also requires a period of rapid political change to generate observable pre/post differences; it is less informative for regimes with stable, long-standing authoritarian control where falsification equilibria have already been reached. Finally, the approach identifies *patterns* consistent with falsification but cannot precisely decompose the relative contributions of falsification, selection, and genuine attitude change without supplementary experimental evidence.

## Implications for Comparative Survey Research

The findings carry concrete implications for scholars working with survey data in autocratizing contexts.

First, researchers using ABS, World Values Survey, Afrobarometer, or Latinobarometro data in regimes undergoing democratic erosion should apply sensitivity gradient checks before interpreting observed attitude shifts at face value. If high-sensitivity items (trust in coercive institutions) show larger regime-favorable shifts than low-sensitivity items (abstract democratic evaluations), the observed trust increase may reflect measurement distortion rather than genuine legitimacy gains. The within-instrument divergence documented here, with trust in police increasing by half a standard deviation while democracy suitability declined by a comparable magnitude, provides a benchmark for the magnitude of distortion possible during rapid autocratization.

Second, the flipped correlation diagnostic can be applied to any survey containing both democratic commitment and regime satisfaction items. When the standard negative correlation reverses, it signals that the cost structure of honest survey response has crossed a threshold beyond which standard interpretive frameworks no longer apply. Researchers interpreting cross-national variation in the critical citizens relationship should, at minimum, condition on the political conditions of survey administration and attend to whether positive correlations cluster in repressive contexts. The decomposition by democratic conception type provides additional leverage: if the reversal is concentrated among procedural democrats rather than substantive-conception respondents, co-optation is unlikely to be the dominant mechanism.

Third, existing findings in the backsliding literature that rely on post-repression survey data may warrant reinterpretation. Research on the relationship between public support and democratic survival [@Claassen2020-hk] and on how polarization shapes regime support [@Davis2025-np] depends on the assumption that survey measures capture genuine attitudes rather than strategic responses. When international observers and scholars interpret survey-based legitimacy claims at face value, they may inadvertently reinforce the informational strategies that autocracies deploy [@Dukalskis2017-md]. Cross-national studies reporting elevated trust or satisfaction in autocratizing regimes, including work drawing on data from Myanmar post-2021 and Russia post-2022, should consider whether the observed levels reflect genuine attitudes or the sensitivity gradient dynamics documented here. The Turkey replication in Section 4.6 suggests that the same gradient emerges in an independent case with a different survey instrument and distinct form of autocratization; Online Appendix J extends this analysis with item non-response diagnostics for both Turkey and Russia, showing that democracy items exhibit systematically higher non-response than trust items, which in turn exceed apolitical controls. The framework is immediately applicable: sensitivity rankings can be constructed for trust items in any cross-national survey battery, and the correlation diagnostic requires only democratic commitment and satisfaction items that are standard across all major survey programs. As scholars continue to debate whether democratic backsliding constitutes a global trend or a measurement artifact [@Waldner2018-yw], the sensitivity gradient provides a concrete tool for adjudicating between these possibilities at the case level.

## Limitations

The within-wave comparison is a quasi-experiment, not a true experiment. Respondents were not randomly assigned to fieldwork periods, and the gap period complicates attribution to the NSL specifically. The analysis cannot determine the precise mix of preference falsification and compositional selection, nor cleanly separate the NSL's contribution from concurrent shocks. The sub-sample sizes ($N_{\text{Protest}} = 473$; $N_{\text{Post-NSL}} = 676$) are adequate for the moderate-to-large effects observed but limit the precision of subgroup analyses. Finally, while the cross-national replication in Turkey (Section 4.6) and additional WVS evidence from Russia (Online Appendix J) demonstrate that the sensitivity gradient generalizes beyond a single case, both primary cases involve rapid, dramatic autocratization. The Russia evidence is suggestive but limited: WVS Waves 6 (2011) and 7 (2017) bracket the post-Crimea annexation period, not the more dramatic post-2022 autocratization, and evidence for the latter relies on published Levada Center tracking data rather than individual-level microdata. The framework's applicability to gradual erosion from within, as in Hungary or Poland, remains to be established empirically.

## Boundary Conditions and Scope

The sensitivity gradient framework is not a universal diagnostic; its power depends on identifiable features of the political and survey context. Explicitly specifying these scope conditions clarifies where the framework offers the most leverage and where alternative approaches are needed.

The framework is most informative when five conditions are met. First, autocratization is rapid, with a clear transition period (typically under five years) that generates observable before/after variation. Second, survey fieldwork spans the critical period or successive waves bracket it closely, providing the temporal leverage needed to detect shifts. Third, the survey instrument remains constant across periods, ruling out item redesign as a confound. Fourth, the trust battery includes items varying in coercive salience---trust in police, government, courts, and parliament occupy distinct positions on the coercion spectrum, and this variation is what generates the gradient. Fifth, democratic evaluation items (suitability, satisfaction, or abstract regime preferences) are available to anchor the low-sensitivity end of the gradient.

The framework is less informative in several contexts. Gradual erosion over decades without clear inflection points---as may characterize the slow hollowing of democratic norms in some hybrid regimes---reduces the within-instrument variation needed to detect differential shifts. Long-consolidated autocracies at stable falsification equilibria pose a different challenge: when respondents have already fully internalized the cost structure of survey response, the gradient may reflect the equilibrium level of distortion rather than a detectable shift. Survey redesigns that alter item wording, response scales, or battery composition between waves confound item-level comparisons. Regimes with uniform totalitarian control, where all institutions are equally associated with coercion, eliminate the within-instrument variation that generates the gradient. Finally, surveys missing either the trust items or the democratic evaluation items cannot support the core diagnostic comparison.

The Hong Kong case offers identification leverage unavailable in standard cross-wave designs: the within-wave fieldwork split holds the instrument, country, and survey wave constant while the political environment shifts, approximating a natural experiment. Even here, compositional selection and preference falsification cannot be cleanly separated, but the sensitivity gradient's predictive power---that trust in police (ranked 1 for coercive salience) inflates most while trust in courts (ranked 6) remains stable---is difficult to explain through selection alone, which predicts uniform shifts across all trust items. The Turkey replication (Section 4.6) suggests that the gradient pattern emerges in cross-wave comparisons as well, though with reduced precision due to the longer time gap between fieldwork waves and the absence of within-wave temporal variation. Whether the framework can detect subtler distortion in cases of gradual democratic backsliding---Hungary, Poland, or the Philippines---remains an open empirical question that future research should address.

## A Practical Diagnostic Toolkit

@tbl-toolkit operationalizes the sensitivity gradient framework as a diagnostic checklist. Researchers analyzing survey data from autocratizing contexts should check for these patterns before interpreting trust increases as genuine legitimacy gains. No single signal is definitive, but multiple converging signals---as in Hong Kong, where all five diagnostics flag distortion---provide strong evidence of measurement distortion. The checklist can be applied with varying data structures: ideal within-wave splits (as in the ABS Hong Kong case) offer the strongest identification, but standard cross-wave comparisons (as in the Turkey WVS case) can still yield informative gradient patterns when the intervening period includes a clear autocratization shock.

```{r}
#| label: tbl-toolkit
#| tbl-cap: "Diagnostic checklist for survey distortion in autocratizing contexts. HK = Hong Kong (ABS W5), TR = Turkey (WVS W6--W7), RU = Russia (WVS W6--W7), VEN = Venezuela (LBS 2015--2018), NIC = Nicaragua (LBS 2015--2018), BFA = Burkina Faso (Afrobarometer R9)."

toolkit <- tibble(
  `Diagnostic signal` = c(
    "Sensitivity gradient",
    "Trust--democracy divergence",
    "Critical citizens reversal",
    "Differential non-response",
    "Implausible climate shifts"
  ),
  `How to check` = c(
    "Rank trust items by coercive role; correlate rank with observed \\(\\Delta\\)",
    "Compare \\(\\Delta\\) trust in police vs. \\(\\Delta\\) democracy suitability",
    "Compute \\(r\\)(dem.\\ preference, dem.\\ satisfaction)",
    "Compare \\% missing: democracy items vs.\\ trust items",
    "Check ``free speech'' perception against objective restrictions"
  ),
  `Red flag threshold` = c(
    "\\(r < -0.5\\)",
    "Opposite signs, \\(|d| > 0.3\\)",
    "\\(r > 0\\) in autocratizing context",
    "Gap \\(> 3\\) pp",
    "Positive shift during crackdown"
  ),
  HK = c(
    "\\checkmark",
    "\\checkmark",
    "\\checkmark",
    "\\checkmark",
    "\\checkmark"
  ),
  TR = c(
    "\\checkmark",
    "\\checkmark",
    "\\checkmark",
    "\\texttildelow",
    "--"
  ),
  RU = c(
    "\\texttildelow",
    "\\texttildelow",
    "\\checkmark",
    "\\texttildelow",
    "--"
  ),
  VEN = c(
    "\\texttimes",
    "\\texttimes",
    "--",
    "--",
    "--"
  ),
  NIC = c(
    "\\texttimes",
    "\\texttimes",
    "--",
    "--",
    "--"
  ),
  BFA = c(
    "\\texttildelow",
    "\\texttildelow",
    "\\texttimes",
    "\\texttimes",
    "--"
  )
)

toolkit |>
  kable(
    booktabs = TRUE,
    escape = FALSE,
    align = c("l", "l", "l", "c", "c", "c", "c", "c", "c")
  ) |>
  kable_styling(latex_options = c("hold_position", "scale_down"), font_size = 9) |>
  column_spec(1, width = "2.5cm") |>
  column_spec(2, width = "4cm") |>
  column_spec(3, width = "2.5cm") |>
  column_spec(4:9, width = "0.7cm") |>
  add_header_above(c(" " = 3, "Positive cases" = 3, "Inverse/null cases" = 3)) |>
  footnote(
    symbol = c(
      "\\\\checkmark = signal present; \\\\texttildelow = suggestive/partial; \\\\texttimes = signal absent; -- = untestable with available data."
    ),
    general = c(
      "Multiple converging signals provide stronger evidence than any single diagnostic.",
      "The checklist is designed for use with standard cross-national survey batteries (ABS, WVS, Afrobarometer, Latinobarómetro)."
    ),
    general_title = "Note: ",
    escape = FALSE,
    footnote_as_chunk = TRUE
  )
```

@fig-five-case-summary summarizes the gradient correlation across all five cases, illustrating the full range from strong falsification signal to genuine collapse.

```{r}
#| label: fig-five-case-summary
#| fig-cap: "The sensitivity gradient across five cases. Each point plots the gradient correlation ($r$) between pre-specified item sensitivity rank and observed Cohen's $d$. Cases to the left show the predicted falsification signature (coercive institutions inflate most). Cases near zero or to the right show null or inverted gradients, consistent with genuine collapse or popular support for the regime change. Color and shape indicate the type of autocratization shock."
#| fig-width: 10
#| fig-height: 4.5
#| out-width: "90%"

knitr::include_graphics("../analysis/figures/fig_five_case_summary.pdf")
```

The toolkit is designed to be conservative: each diagnostic has a clear threshold, and researchers should report which signals are present, absent, or untestable given their data. The first two diagnostics---the sensitivity gradient and the trust--democracy divergence---are the most portable, requiring only trust items and at least one democratic evaluation item measured at two time points. The critical citizens reversal requires both democratic preference and democratic satisfaction items in the same survey. Differential non-response and implausible climate shifts provide additional leverage when item-level missingness data and objective measures of political conditions are available. When most diagnostics flag distortion, the burden of proof shifts: scholars claiming genuine legitimacy gains must explain why the pattern of observed shifts so closely tracks the predictions of a falsification model.

# Conclusion

Surveys are essential tools for studying democratic backsliding, but they require validity checks calibrated to the political environment. This article has developed and tested a sensitivity gradient framework for identifying when survey measures in autocratizing regimes produce false positives for regime support. The framework exploits a simple theoretical insight: because the cost of honest response varies across survey items as a function of their political sensitivity, preference falsification generates a predictable within-instrument pattern of distortion. High-sensitivity items inflate in the regime-favorable direction; low-sensitivity items continue to track genuine sentiment. This divergence provides a diagnostic that requires no experimental design, works with standard survey batteries, and can be applied retrospectively to data already collected.

The Hong Kong natural experiment provides proof-of-concept that the sensitivity gradient constitutes a detectable pattern under rapid autocratization. When trust in police increases by half a standard deviation in the months following mass police violence against protesters, the measure is capturing something other than genuine institutional confidence. The simultaneous collapse of democracy suitability, the reversal of the critical citizens correlation among procedural democrats, the implausible increase in reported free speech, and the age gradient contradicting conservative revaluation converge on evidence consistent with measurement distortion: the post-NSL survey environment produced systematic false positives for regime support on politically sensitive items. The Turkey replication—using a different survey instrument, autocratization trajectory, and cross-wave design—strengthens the inference that this pattern generalizes beyond single-case idiosyncrasy. If scholars cannot distinguish these false positives from genuine attitude change, they risk misdiagnosing authoritarian consolidation as popular legitimacy—a consequential error for both academic understanding and policy response.

The sensitivity gradient approach does not resolve every measurement challenge in authoritarian survey research. It works best when repression is uneven, political change is rapid, and surveys contain items spanning a range of political sensitivity. While proof-of-concept relies on Hong Kong's unique natural experiment, the Turkey replication (Section 4.6) demonstrates that the core diagnostic patterns—differential item inflation and trust-democracy divergence—emerge in standard cross-wave comparisons as well, and preliminary Russia evidence (Online Appendix J) shows consistent non-response patterns. For the growing number of cases where these conditions obtain—not only Hong Kong and Turkey (as demonstrated here) but potentially Myanmar, Russia, and other rapid autocratization cases—the sensitivity gradient offers an immediately applicable tool for assessing whether the data can be trusted to mean what it appears to say.

# References {.unnumbered}

\singlespacing

::: {#refs}
:::
