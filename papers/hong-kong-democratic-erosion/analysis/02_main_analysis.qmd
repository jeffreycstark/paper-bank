---
title: "02 - Main Analysis: Covariate Adjustment, Reweighting, and Mechanism Tests"
subtitle: "Addressing identification, item sensitivity, and falsification tests"
format: html
execute:
  echo: true
  warning: false
  message: false
  cache: true
---

```{r setup}
library(tidyverse)
library(knitr)
library(kableExtra)
library(broom)
```

# Load Prepared Data

```{r load-data}
load("results/prepared_data.RData")

hk5_analysis <- hk5 |>
  filter(period %in% c("Protest", "Post-NSL")) |>
  mutate(
    period = droplevels(period),
    post_nsl = as.numeric(period == "Post-NSL")
  )

cat("Protest:", sum(hk5_analysis$period == "Protest"),
    "| Post-NSL:", sum(hk5_analysis$period == "Post-NSL"), "\n")
```

# ============================================================
# SECTION 1: Covariate-Adjusted Estimates (R2 Issue 1a)
# ============================================================
# OLS with age, gender, education controls for the 4 primary outcomes.
# This goes in the main text.

```{r covariate-check}
# Check which demographic variables are available
cat("=== Available demographics ===\n")
demo_candidates <- c("age", "female", "gender", "education", "education_level",
                      "education_years", "income", "age_group", "urban_rural")
for (v in demo_candidates) {
  if (v %in% names(hk5_analysis)) {
    cat(v, ": ", sum(!is.na(hk5_analysis[[v]])), "non-missing /",
        nrow(hk5_analysis), "\n")
    if (is.numeric(hk5_analysis[[v]])) {
      cat("  Range:", range(hk5_analysis[[v]], na.rm = TRUE), "\n")
    } else {
      print(table(hk5_analysis[[v]], useNA = "ifany"))
    }
  } else {
    cat(v, ": NOT in dataset\n")
  }
}

# Clean education_level: recode 97/98/99/11 to NA, then use as continuous ordinal
if ("education_level" %in% names(hk5_analysis)) {
  hk5_analysis <- hk5_analysis |>
    mutate(
      education_level_clean = case_when(
        education_level %in% c(-1, 11, 97, 98, 99) ~ NA_real_,
        TRUE ~ as.numeric(education_level)
      )
    )
  cat("\neducation_level_clean created: ",
      sum(!is.na(hk5_analysis$education_level_clean)), "valid /",
      nrow(hk5_analysis), "\n")
  cat("  Range:", range(hk5_analysis$education_level_clean, na.rm = TRUE), "\n")
}
```

```{r primary-outcomes}
# Pre-specify 4 primary outcomes (R2 Issue 6: distinguish primary vs exploratory)
primary_outcomes <- c(
  "trust_police",
  "trust_national_government",
  "democracy_suitability",
  "gov_free_to_organize"
)

primary_labels <- c(
  trust_police = "Trust in Police",
  trust_national_government = "Trust in National Government",
  democracy_suitability = "Democracy Suitability",
  gov_free_to_organize = "Freedom to Organize"
)

# Verify all exist
stopifnot(all(primary_outcomes %in% names(hk5_analysis)))
```

```{r ols-adjusted}
# Determine which covariates to use based on availability
# Build covariate formula string dynamically
covariates <- c()
if ("age" %in% names(hk5_analysis) && sum(!is.na(hk5_analysis$age)) > 100) {
  covariates <- c(covariates, "age")
}
if ("female" %in% names(hk5_analysis) && sum(!is.na(hk5_analysis$female)) > 100) {
  covariates <- c(covariates, "female")
} else if ("gender" %in% names(hk5_analysis) && sum(!is.na(hk5_analysis$gender)) > 100) {
  covariates <- c(covariates, "gender")
}
# Education: prefer education_level_clean (SE5, ordinal 1-10) if available;
# fallback to education_years (continuous), then "education" (generic)
if ("education_level_clean" %in% names(hk5_analysis) &&
    sum(!is.na(hk5_analysis$education_level_clean)) > 100) {
  covariates <- c(covariates, "education_level_clean")
} else if ("education_years" %in% names(hk5_analysis) &&
           sum(!is.na(hk5_analysis$education_years)) > 100) {
  covariates <- c(covariates, "education_years")
} else if ("education" %in% names(hk5_analysis) &&
           sum(!is.na(hk5_analysis$education)) > 100) {
  covariates <- c(covariates, "education")
}

cat("Covariates for adjusted models:", paste(covariates, collapse = ", "), "\n")

# Run OLS for each primary outcome: unadjusted + adjusted
ols_results <- map_dfr(primary_outcomes, function(outcome) {
  # Unadjusted
  f_unadj <- as.formula(paste(outcome, "~ post_nsl"))
  m_unadj <- lm(f_unadj, data = hk5_analysis)
  t_unadj <- tidy(m_unadj) |> filter(term == "post_nsl")

  # Adjusted
  if (length(covariates) > 0) {
    f_adj <- as.formula(paste(outcome, "~ post_nsl +", paste(covariates, collapse = " + ")))
    m_adj <- lm(f_adj, data = hk5_analysis)
    t_adj <- tidy(m_adj) |> filter(term == "post_nsl")
    n_adj <- nobs(m_adj)
    r2_adj <- glance(m_adj)$r.squared
  } else {
    t_adj <- t_unadj
    n_adj <- nobs(m_unadj)
    r2_adj <- NA
  }

  tibble(
    outcome = outcome,
    label = primary_labels[outcome],
    # Unadjusted
    b_unadj = t_unadj$estimate,
    se_unadj = t_unadj$std.error,
    p_unadj = t_unadj$p.value,
    n_unadj = nobs(m_unadj),
    # Adjusted
    b_adj = t_adj$estimate,
    se_adj = t_adj$std.error,
    p_adj = t_adj$p.value,
    n_adj = n_adj,
    r2_adj = r2_adj
  )
})

ols_results |>
  mutate(across(c(b_unadj, se_unadj, b_adj, se_adj, r2_adj), ~round(.x, 3)),
         p_unadj = format.pval(p_unadj, digits = 3),
         p_adj = format.pval(p_adj, digits = 3)) |>
  select(label, b_unadj, se_unadj, p_unadj, b_adj, se_adj, p_adj, n_adj) |>
  kable(
    col.names = c("Outcome", "b (unadj)", "SE", "p", "b (adj)", "SE", "p", "N"),
    caption = "OLS estimates: Post-NSL effect on primary outcomes (unadjusted and covariate-adjusted)",
    booktabs = TRUE
  ) |>
  kable_styling(latex_options = c("hold_position"))
```

```{r ols-full-models}
# Print full model summaries for appendix
for (outcome in primary_outcomes) {
  cat("\n\n### Full adjusted model:", primary_labels[outcome], "\n\n")
  if (length(covariates) > 0) {
    f_adj <- as.formula(paste(outcome, "~ post_nsl +", paste(covariates, collapse = " + ")))
  } else {
    f_adj <- as.formula(paste(outcome, "~ post_nsl"))
  }
  m <- lm(f_adj, data = hk5_analysis)
  print(summary(m))
}
```


# ============================================================
# SECTION 2: Entropy Balancing / IPW (R2 Issue 1b)
# ============================================================
# Reweight Post-NSL sample to match Protest on demographics

```{r reweighting}
# Try WeightIt first; fall back to manual IPW if not installed
if (!requireNamespace("WeightIt", quietly = TRUE)) {
  stop(
    "Package 'WeightIt' is required for entropy balancing. ",
    "Install it with install.packages('WeightIt') and re-run."
  )
}
library(WeightIt)

# Build formula for balancing
if (length(covariates) > 0) {
  bal_formula <- as.formula(paste("post_nsl ~", paste(covariates, collapse = " + ")))
} else {
  cat("WARNING: No covariates available for reweighting. Skipping.\n")
  bal_formula <- NULL
}

if (!is.null(bal_formula)) {
  # Complete cases for balancing variables
  bal_data <- hk5_analysis |>
    select(all_of(c("post_nsl", "period", covariates, primary_outcomes))) |>
    drop_na(all_of(covariates))

  cat("Complete cases for reweighting:", nrow(bal_data), "\n")

  # Entropy balancing
  wb <- tryCatch({
    weightit(bal_formula, data = bal_data, method = "ebal",
             estimand = "ATT")
  }, error = function(e) {
    cat("Entropy balancing failed:", e$message, "\n")
    cat("Falling back to IPW (logistic regression)...\n")
    weightit(bal_formula, data = bal_data, method = "ps",
             estimand = "ATT")
  })

  cat("\n=== Balance summary ===\n")
  print(summary(wb))

  # Reweighted estimates
  bal_data$weights <- wb$weights

  reweighted_results <- map_dfr(primary_outcomes, function(outcome) {
    f <- as.formula(paste(outcome, "~ post_nsl"))
    m <- lm(f, data = bal_data, weights = weights)
    t <- tidy(m) |> filter(term == "post_nsl")
    tibble(
      outcome = outcome,
      label = primary_labels[outcome],
      b_reweighted = t$estimate,
      se_reweighted = t$std.error,
      p_reweighted = t$p.value,
      n = nobs(m)
    )
  })

  reweighted_results |>
    mutate(across(c(b_reweighted, se_reweighted), ~round(.x, 3)),
           p_reweighted = format.pval(p_reweighted, digits = 3)) |>
    kable(
      col.names = c("Outcome", "Label", "b (reweighted)", "SE", "p", "N"),
      caption = "Reweighted estimates (entropy balancing on demographics)",
      booktabs = TRUE
    ) |>
    kable_styling(latex_options = c("hold_position"))
}
```

```{r combined-estimates-table}
# Combine unadjusted, adjusted, and reweighted for main text presentation
if (exists("reweighted_results")) {
  combined_table <- ols_results |>
    left_join(reweighted_results |> select(outcome, b_reweighted, se_reweighted, p_reweighted),
              by = "outcome") |>
    select(label, b_unadj, se_unadj, p_unadj,
           b_adj, se_adj, p_adj,
           b_reweighted, se_reweighted, p_reweighted) |>
    mutate(across(where(is.numeric), ~round(.x, 3)),
           across(starts_with("p_"), ~format.pval(as.numeric(.x), digits = 3)))

  combined_table |>
    kable(
      col.names = c("Outcome",
                     "b", "SE", "p",
                     "b", "SE", "p",
                     "b", "SE", "p"),
      caption = "Post-NSL effect estimates: unadjusted, covariate-adjusted, and reweighted",
      booktabs = TRUE
    ) |>
    kable_styling(latex_options = c("scale_down", "hold_position")) |>
    add_header_above(c(" " = 1, "Unadjusted" = 3, "Covariate-Adjusted" = 3, "Reweighted" = 3))
} else {
  cat("Reweighted results not available. Showing unadjusted + adjusted only.\n")
}
```


# ============================================================
# SECTION 3: Falsification Tests (R2 Issue 1c)
# ============================================================
# Pre-specify items that SHOULD NOT jump if NSL/fear is the driver

```{r falsification-tests}
# Falsification test: items that should be insensitive to political repression
# These are "negative control outcomes" — if they jump, it suggests confounding
# rather than NSL-specific effects

falsification_vars <- c()

# Check which candidates are available
candidates <- c(
  "rich_poor_treated_equally",  # Perception of equality — not politically sensitive
  "political_interest",         # General interest — shouldn't spike from fear
  "trust_courts"                # Already noted as stable (d≈0.03) — less coercive institution
)

for (v in candidates) {
  if (v %in% names(hk5_analysis)) {
    n_valid <- sum(!is.na(hk5_analysis[[v]]))
    if (n_valid > 100) {
      falsification_vars <- c(falsification_vars, v)
      cat("Falsification variable:", v, "- N =", n_valid, "\n")
    }
  }
}

# Additional candidates from data
extra_candidates <- c(
  "efficacy_ability_participate",  # Political efficacy — may or may not be sensitive
  "pol_discuss"                     # Frequency of political discussion
)

for (v in extra_candidates) {
  if (v %in% names(hk5_analysis)) {
    n_valid <- sum(!is.na(hk5_analysis[[v]]))
    if (n_valid > 100) {
      cat("Additional candidate:", v, "- N =", n_valid, "\n")
    }
  }
}

# Run t-tests + Cohen's d for falsification variables
if (length(falsification_vars) > 0) {
  falsification_results <- map_dfr(falsification_vars, function(var) {
    protest <- hk5_analysis |> filter(period == "Protest") |> pull(!!sym(var)) |> na.omit()
    postnsl <- hk5_analysis |> filter(period == "Post-NSL") |> pull(!!sym(var)) |> na.omit()

    if (length(protest) < 10 | length(postnsl) < 10) return(NULL)

    tt <- t.test(protest, postnsl)
    pooled_sd <- sqrt(((length(protest) - 1) * sd(protest)^2 +
                         (length(postnsl) - 1) * sd(postnsl)^2) /
                        (length(protest) + length(postnsl) - 2))
    d <- (mean(postnsl) - mean(protest)) / pooled_sd

    tibble(
      variable = var,
      protest_mean = mean(protest),
      postnsl_mean = mean(postnsl),
      delta = mean(postnsl) - mean(protest),
      cohens_d = d,
      p_value = tt$p.value,
      sig = case_when(
        tt$p.value < 0.001 ~ "***",
        tt$p.value < 0.01  ~ "**",
        tt$p.value < 0.05  ~ "*",
        TRUE ~ "ns"
      )
    )
  })

  cat("\n=== Falsification Test Results ===\n")
  cat("Expectation: these items should show small/non-significant effects\n")
  cat("if the observed shifts are driven by NSL-specific mechanisms.\n\n")

  falsification_results |>
    mutate(across(c(protest_mean, postnsl_mean, delta, cohens_d), ~round(.x, 3)),
           p_value = format.pval(p_value, digits = 3)) |>
    kable(
      col.names = c("Variable", "Protest Mean", "Post-NSL Mean",
                     "Delta", "Cohen's d", "p-value", "Sig"),
      caption = "Falsification tests: politically insensitive items",
      booktabs = TRUE
    ) |>
    kable_styling(latex_options = c("hold_position"))
}
```


# ============================================================
# SECTION 4: Item Sensitivity Gradient (R2 Issue 2a)
# ============================================================
# Test the prediction: coercive institutions show biggest trust
# "inflation," courts least, abstract evaluations least.

```{r sensitivity-gradient}
# Pre-specified hierarchy of item sensitivity
# Theory: items asking about coercive institutions under authoritarian conditions
# feel more dangerous to answer critically
sensitivity_hierarchy <- tribble(
  ~variable, ~category, ~sensitivity_rank, ~label,
  "trust_police",               "Coercive institution",     1, "Trust in Police",
  "trust_national_government",  "Coercive institution",     1, "Trust in Nat'l Government",
  "trust_president",            "Executive",                2, "Trust in President/CE",
  "trust_parliament",           "Legislature",              3, "Trust in Parliament",
  "trust_military",             "Military",                 3, "Trust in Military",
  "trust_courts",               "Judiciary",                4, "Trust in Courts",
  "democracy_suitability",      "Abstract evaluation",      5, "Democracy Suitability",
  "dem_always_preferable",      "Abstract commitment",      5, "Democracy Preferable",
  "democracy_satisfaction",     "Abstract satisfaction",     5, "Democratic Satisfaction"
)

# Filter to available variables
sensitivity_hierarchy <- sensitivity_hierarchy |>
  filter(variable %in% names(hk5_analysis))

# Compute Cohen's d for each
sensitivity_results <- map_dfr(sensitivity_hierarchy$variable, function(var) {
  protest <- hk5_analysis |> filter(period == "Protest") |> pull(!!sym(var)) |> na.omit()
  postnsl <- hk5_analysis |> filter(period == "Post-NSL") |> pull(!!sym(var)) |> na.omit()

  if (length(protest) < 10 | length(postnsl) < 10) return(NULL)

  pooled_sd <- sqrt(((length(protest) - 1) * sd(protest)^2 +
                       (length(postnsl) - 1) * sd(postnsl)^2) /
                      (length(protest) + length(postnsl) - 2))
  d <- (mean(postnsl) - mean(protest)) / pooled_sd

  tibble(variable = var, cohens_d = d)
}) |>
  left_join(sensitivity_hierarchy, by = "variable") |>
  arrange(sensitivity_rank)

cat("\n=== Item Sensitivity Gradient ===\n")
cat("Prediction: coercive institution trust items (police, government) show\n")
cat("LARGEST positive d (trust inflation). Courts and abstract evaluations\n")
cat("show smallest or negative d.\n\n")

sensitivity_results |>
  select(label, category, sensitivity_rank, cohens_d) |>
  mutate(cohens_d = round(cohens_d, 3)) |>
  kable(
    col.names = c("Item", "Category", "Sensitivity Rank", "Cohen's d (Post-NSL − Protest)"),
    caption = "Item sensitivity gradient: effect sizes ordered by predicted sensitivity",
    booktabs = TRUE
  ) |>
  kable_styling(latex_options = c("hold_position"))

# Test: correlation between sensitivity rank and Cohen's d direction
# For trust items (higher d = more inflation), coercive should have highest d
trust_items <- sensitivity_results |> filter(str_detect(variable, "trust"))
cat("\nTrust items only — correlation between sensitivity rank and Cohen's d:\n")
cat("r =", round(cor(trust_items$sensitivity_rank, trust_items$cohens_d, use = "complete.obs"), 3), "\n")
cat("(Negative r = higher sensitivity rank associated with lower d, as predicted)\n")
```

```{r sensitivity-figure}
#| fig-cap: "Item sensitivity gradient: Cohen's d by predicted sensitivity category"
#| fig-width: 10
#| fig-height: 6

sensitivity_results |>
  mutate(
    label = fct_reorder(label, cohens_d),
    direction = ifelse(cohens_d > 0, "Increase", "Decrease")
  ) |>
  ggplot(aes(x = cohens_d, y = label, fill = category)) +
  geom_col(alpha = 0.8) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey50") +
  scale_fill_brewer(palette = "Set2") +
  labs(
    x = "Cohen's d (Post-NSL − Protest)",
    y = NULL,
    fill = "Item Category",
    title = "Item Sensitivity Gradient",
    subtitle = "Coercive institution trust items should show largest positive shifts"
  ) +
  theme_minimal(base_size = 11) +
  theme(legend.position = "bottom")
```


# ============================================================
# SECTION 5: DK/Refuse Diagnostic (R2 Issue 2c)
# ============================================================
# Check if ABS provides item nonresponse codes

```{r dk-refuse-check}
# Check the raw data for potential DK/Refuse indicators
# ABS typically codes: 7 = Can't choose, 8 = Decline to answer, 9 = Missing
# But harmonized data may have already converted these to NA

# Check if there are very specific values that might indicate DK/refuse
# in the trust variables before they were recoded
cat("=== Checking for DK/Refuse patterns ===\n\n")

# Look at the distribution of trust_police values
for (var in c("trust_police", "trust_national_government", "trust_courts")) {
  if (var %in% names(hk5_analysis)) {
    cat(var, ":\n")
    cat("  Unique values:", sort(unique(hk5_analysis[[var]])), "\n")
    cat("  NA count:", sum(is.na(hk5_analysis[[var]])), "\n")

    # Compare NA rates across periods
    na_protest <- hk5_analysis |>
      filter(period == "Protest") |>
      summarise(na_rate = mean(is.na(!!sym(var))))
    na_postnsl <- hk5_analysis |>
      filter(period == "Post-NSL") |>
      summarise(na_rate = mean(is.na(!!sym(var))))

    cat("  NA rate (Protest):", round(na_protest$na_rate, 3), "\n")
    cat("  NA rate (Post-NSL):", round(na_postnsl$na_rate, 3), "\n\n")
  }
}

# Compare item nonresponse rates for sensitive vs non-sensitive items
cat("\n=== Item Nonresponse Rates by Period ===\n")
sensitive_items <- c("trust_police", "trust_national_government", "trust_president")
insensitive_items <- c("trust_courts", "rich_poor_treated_equally", "political_interest")
all_check_items <- c(sensitive_items, insensitive_items)
all_check_items <- all_check_items[all_check_items %in% names(hk5_analysis)]

nr_comparison <- map_dfr(all_check_items, function(var) {
  tibble(
    variable = var,
    sensitive = var %in% sensitive_items,
    na_protest = mean(is.na(hk5_analysis[[var]][hk5_analysis$period == "Protest"])),
    na_postnsl = mean(is.na(hk5_analysis[[var]][hk5_analysis$period == "Post-NSL"])),
    na_diff = na_postnsl - na_protest
  )
})

nr_comparison |>
  mutate(across(c(na_protest, na_postnsl, na_diff), ~round(.x, 3))) |>
  kable(
    col.names = c("Variable", "Sensitive?", "NA% Protest", "NA% Post-NSL", "Diff"),
    caption = "Item nonresponse rates by period (proxy for DK/Refuse)",
    booktabs = TRUE
  ) |>
  kable_styling(latex_options = c("hold_position"))
```


# ============================================================
# SECTION 6: Correlation Harmonization (R2 Issue 3)
# ============================================================
# Compute the critical citizens correlation precisely for manuscript

```{r correlation-fix}
cat("=== Critical Citizens Correlation: Precise Computation ===\n\n")

# 1. Overall HK Wave 5
hk5_cc <- hk5 |>
  filter(!is.na(dem_always_preferable), !is.na(democracy_satisfaction))
overall_r <- cor.test(hk5_cc$dem_always_preferable, hk5_cc$democracy_satisfaction)
cat("Overall HK W5: r =", round(overall_r$estimate, 3),
    " [", round(overall_r$conf.int[1], 3), ",", round(overall_r$conf.int[2], 3), "]",
    " N =", nrow(hk5_cc), " p =", format.pval(overall_r$p.value, digits = 3), "\n")

# 2. By period
for (p in c("Protest", "Gap", "Post-NSL")) {
  sub <- hk5_cc |> filter(period == p)
  if (nrow(sub) > 10) {
    r_test <- cor.test(sub$dem_always_preferable, sub$democracy_satisfaction)
    cat(p, ": r =", round(r_test$estimate, 3),
        " [", round(r_test$conf.int[1], 3), ",", round(r_test$conf.int[2], 3), "]",
        " N =", nrow(sub), " p =", format.pval(r_test$p.value, digits = 3), "\n")
  }
}

# 3. Cross-national comparison (Wave 5 only, for "only positive country" claim)
cat("\n=== Cross-national correlations (Wave 5 only) ===\n")
w5_cc <- d |>
  filter(wave == 5, !is.na(dem_always_preferable), !is.na(democracy_satisfaction)) |>
  group_by(country_name) |>
  filter(n() >= 30) |>
  summarise(
    r = cor(dem_always_preferable, democracy_satisfaction, use = "complete.obs"),
    n = n(),
    .groups = "drop"
  ) |>
  arrange(desc(r))

w5_cc |>
  mutate(r = round(r, 3)) |>
  kable(caption = "Critical citizens correlation by country (Wave 5 only)")

cat("\nCountries with positive r:", paste(w5_cc$country_name[w5_cc$r > 0], collapse = ", "), "\n")
cat("Number of countries:", nrow(w5_cc), "\n")

# 4. HK across waves (for the "r ≈ 0.13" in descriptive analysis)
cat("\n=== HK correlation across waves ===\n")
hk_cc_waves <- hk |>
  filter(!is.na(dem_always_preferable), !is.na(democracy_satisfaction)) |>
  group_by(wave) |>
  summarise(
    r = cor(dem_always_preferable, democracy_satisfaction, use = "complete.obs"),
    n = n(),
    .groups = "drop"
  )

hk_cc_waves |>
  mutate(r = round(r, 3)) |>
  kable(caption = "HK critical citizens correlation by wave")

# Cross-wave overall
hk_all_cc <- hk |>
  filter(!is.na(dem_always_preferable), !is.na(democracy_satisfaction))
r_all <- cor(hk_all_cc$dem_always_preferable, hk_all_cc$democracy_satisfaction, use = "complete.obs")
cat("\nHK overall (all waves): r =", round(r_all, 3), "\n")
```


# ============================================================
# SECTION 7: FDR Correction (R2 Issue 6)
# ============================================================

```{r fdr-correction}
# Load the full NSL t-test results
load("results/descriptive_results.RData")

# Apply Benjamini-Hochberg correction
fdr_results <- nsl_tests |>
  mutate(
    p_bh = p.adjust(p_value, method = "BH"),
    sig_bh = case_when(
      p_bh < 0.001 ~ "***",
      p_bh < 0.01  ~ "**",
      p_bh < 0.05  ~ "*",
      TRUE ~ ""
    ),
    primary = variable %in% primary_outcomes
  )

cat("=== FDR-corrected results ===\n")
cat("Variables significant at BH-adjusted p < 0.05:",
    sum(fdr_results$p_bh < 0.05), "of", nrow(fdr_results), "\n")
cat("Variables significant at BH-adjusted p < 0.01:",
    sum(fdr_results$p_bh < 0.01), "of", nrow(fdr_results), "\n\n")

fdr_results |>
  select(variable, primary, cohens_d, p_value, sig, p_bh, sig_bh) |>
  mutate(across(c(cohens_d), ~round(.x, 3)),
         p_value = format.pval(p_value, digits = 3),
         p_bh = format.pval(p_bh, digits = 3)) |>
  kable(
    col.names = c("Variable", "Primary?", "Cohen's d", "p (raw)", "Sig",
                   "p (BH-adj)", "Sig (adj)"),
    caption = "FDR-corrected p-values (Benjamini-Hochberg)",
    booktabs = TRUE
  ) |>
  kable_styling(latex_options = c("scale_down", "hold_position"))
```


# ============================================================
# SECTION 8: Variable Label Mapping (R2 Issue 4)
# ============================================================
# Create consistent human-readable labels for all variables

```{r variable-labels}
var_labels <- tribble(
  ~variable, ~label, ~direction_note,
  "democracy_suitability",      "Democracy Suitability",                "Higher = more suitable",
  "dem_extent_current",         "Current Extent of Democracy",          "Higher = more democratic",
  "dem_country_present_govt",   "Rate Present Govt as Democratic",      "Higher = more democratic",
  "dem_always_preferable",      "Democracy Always Preferable",          "Higher = stronger preference",
  "democracy_satisfaction",     "Democratic Satisfaction",               "Higher = more satisfied",
  "trust_national_government",  "Trust in National Government",         "Higher = more trust",
  "trust_president",            "Trust in President/CE",                "Higher = more trust",
  "trust_parliament",           "Trust in Parliament",                  "Higher = more trust",
  "trust_police",               "Trust in Police",                      "Higher = more trust",
  "trust_military",             "Trust in Military",                    "Higher = more trust",
  "trust_courts",               "Trust in Courts",                      "Higher = more trust",
  "gov_free_to_organize",       "Freedom to Organize",                  "Higher = more free",
  "dem_free_speech",            "Free to Speak Without Fear",           "Higher = more perceived freedom",
  "govt_responds_people",       "Government Responds to People",        "Higher = more responsive",
  "election_free_fair",         "Elections Free and Fair",               "Higher = more fair",
  "system_deserves_support",    "System Deserves Support",              "Higher = more support",
  "system_proud",               "Proud of System",                      "Higher = more proud",
  "system_needs_change",        "System Needs Major Change",            "Higher = more change needed",
  "strongman_rule",             "Support Strongman Rule",               "Higher = more support",
  "military_rule",              "Support Military Rule",                "Higher = more support",
  "single_party_rule",          "Support Single-Party Rule",            "Higher = more support",
  "rich_poor_treated_equally",  "Rich/Poor Treated Equally",            "Higher = more equal",
  "political_interest",         "Political Interest",                   "Higher = more interest",
  "nat_willing_emigrate",       "Willingness to Emigrate",              "Higher = more willing",
  "efficacy_ability_participate","Ability to Participate",               "Higher = more ability",
  "pol_discuss",                "Discuss Politics",                     "Higher = more frequent"
)

# NOTE for manuscript: dem_free_speech = q115 "People are free to speak what they
# think without fear." Higher = more agreement = more perceived free speech.
# The positive d (Protest → Post-NSL increase) means respondents CLAIM MORE
# free speech after the NSL, which is substantively implausible and consistent
# with preference falsification on a politically sensitive item.
cat("\n=== CRITICAL NOTE ===\n")
cat("dem_free_speech (q115): 'People are free to speak without fear'\n")
cat("Higher = more perceived freedom of speech.\n")
cat("Positive d means respondents CLAIM MORE free speech post-NSL.\n")
cat("This is substantively implausible and consistent with preference falsification.\n")
```


# ============================================================
# SECTION 9: Democracy Items Crosstab (Low-Missingness Items)
# ============================================================
# Broader picture of democratic attitudes using items with lower
# missingness than democracy_satisfaction, complementing the
# primary analysis.

```{r democracy-items-crosstab}
# Define the democracy items to examine, ordered by missingness
dem_items <- tribble(
  ~variable, ~label, ~type, ~scale_description,
  "dem_vs_econ", "Democracy vs. Econ. Development", "ordinal",
    "1=Econ definitely more, 2=Econ somewhat, 3=Dem somewhat, 4=Dem definitely, 5=Both equally",
  "dem_vs_equality", "Freedom vs. Equality", "ordinal",
    "1=Ineq definitely, 2=Ineq somewhat, 3=Both equally, 4=Freedom somewhat, 5=Freedom definitely",
  "dem_essential_harmonized", "Most Essential Element of Democracy", "nominal",
    "1=Electoral, 2=Expressive, 3=Redistributive, 4=Basic needs, 5=Good governance",
  "dem_procedural_vs_substantive", "Procedural vs. Substantive Conception", "binary",
    "0=Substantive, 1=Procedural",
  "dem_free_speech", "Free to Speak Without Fear", "ordinal",
    "1=Strongly disagree, 2=Somewhat disagree, 3=Somewhat agree, 4=Strongly agree",
  "dem_always_preferable", "Democracy Always Preferable", "nominal",
    "1=Democracy always, 2=Authoritarian sometimes, 3=Doesn't matter",
  "democracy_satisfaction", "Democratic Satisfaction", "ordinal",
    "1=Not at all satisfied, 2=Not very, 3=Fairly, 4=Very satisfied"
)

# Filter to variables present in the data
dem_items <- dem_items |>
  filter(variable %in% names(hk5_analysis))

# --- Part A: Missingness rates by period ---
dem_missing <- map_dfr(dem_items$variable, function(var) {
  protest_data <- hk5_analysis |> filter(period == "Protest")
  postnsl_data <- hk5_analysis |> filter(period == "Post-NSL")
  tibble(
    variable = var,
    n_protest = nrow(protest_data),
    n_protest_valid = sum(!is.na(protest_data[[var]])),
    pct_missing_protest = mean(is.na(protest_data[[var]])) * 100,
    n_postnsl = nrow(postnsl_data),
    n_postnsl_valid = sum(!is.na(postnsl_data[[var]])),
    pct_missing_postnsl = mean(is.na(postnsl_data[[var]])) * 100
  )
}) |>
  left_join(dem_items |> select(variable, label), by = "variable")

# --- Part B: Effect sizes for ordinal/continuous items ---
dem_effects <- map_dfr(dem_items$variable, function(var) {
  protest <- hk5_analysis |> filter(period == "Protest") |> pull(!!sym(var)) |> na.omit()
  postnsl <- hk5_analysis |> filter(period == "Post-NSL") |> pull(!!sym(var)) |> na.omit()

  if (length(protest) < 10 | length(postnsl) < 10) return(NULL)

  item_type <- dem_items$type[dem_items$variable == var]

  if (item_type %in% c("ordinal", "binary")) {
    tt <- t.test(protest, postnsl)
    pooled_sd <- sqrt(((length(protest) - 1) * sd(protest)^2 +
                         (length(postnsl) - 1) * sd(postnsl)^2) /
                        (length(protest) + length(postnsl) - 2))
    d <- (mean(postnsl) - mean(protest)) / pooled_sd

    tibble(
      variable = var,
      protest_mean = mean(protest),
      postnsl_mean = mean(postnsl),
      delta = mean(postnsl) - mean(protest),
      cohens_d = d,
      p_value = tt$p.value,
      test_type = "t-test",
      n_protest = length(protest),
      n_postnsl = length(postnsl)
    )
  } else {
    # Nominal: chi-squared test
    combined <- hk5_analysis |>
      filter(period %in% c("Protest", "Post-NSL"), !is.na(!!sym(var)))
    ct <- table(combined$period, combined[[var]])
    chi <- chisq.test(ct)

    # Cramér's V
    n <- sum(ct)
    k <- min(nrow(ct), ncol(ct))
    cramers_v <- sqrt(chi$statistic / (n * (k - 1)))

    tibble(
      variable = var,
      protest_mean = NA_real_,
      postnsl_mean = NA_real_,
      delta = NA_real_,
      cohens_d = as.numeric(cramers_v),
      p_value = chi$p.value,
      test_type = "chi-squared (Cramér's V)",
      n_protest = sum(ct["Protest", ]),
      n_postnsl = sum(ct["Post-NSL", ])
    )
  }
}) |>
  left_join(dem_items |> select(variable, label, type), by = "variable")

# --- Part C: Response distributions for nominal items ---
dem_distributions <- map_dfr(
  dem_items$variable[dem_items$type == "nominal"],
  function(var) {
    combined <- hk5_analysis |>
      filter(period %in% c("Protest", "Post-NSL"), !is.na(!!sym(var)))
    combined |>
      group_by(period) |>
      count(value = !!sym(var)) |>
      mutate(pct = n / sum(n) * 100) |>
      ungroup() |>
      mutate(variable = var)
  }
) |>
  left_join(dem_items |> select(variable, label), by = "variable")

# --- Part D: Summary table for manuscript ---
dem_summary_table <- dem_effects |>
  left_join(dem_missing |> select(variable, pct_missing_protest, pct_missing_postnsl),
            by = "variable") |>
  arrange(pct_missing_protest) |>
  select(label, type, n_protest, n_postnsl,
         pct_missing_protest, pct_missing_postnsl,
         protest_mean, postnsl_mean, delta, cohens_d, p_value, test_type)

cat("=== Democracy Items Summary ===\n\n")
dem_summary_table |>
  mutate(
    across(c(protest_mean, postnsl_mean, delta, cohens_d,
             pct_missing_protest, pct_missing_postnsl), ~round(.x, 3)),
    p_value = format.pval(p_value, digits = 3),
    sig = case_when(
      as.numeric(p_value) < 0.001 ~ "***",
      as.numeric(p_value) < 0.01  ~ "**",
      as.numeric(p_value) < 0.05  ~ "*",
      TRUE ~ ""
    )
  ) |>
  kable(
    col.names = c("Variable", "Type", "N (Pre)", "N (Post)",
                   "% Miss (Pre)", "% Miss (Post)",
                   "Mean (Pre)", "Mean (Post)", "Delta",
                   "Effect Size", "p", "Test", ""),
    caption = "Democracy items: pre/post NSL comparison ordered by missingness rate",
    booktabs = TRUE
  ) |>
  kable_styling(latex_options = c("scale_down", "hold_position"))
```

```{r dem-essential-distribution}
# Detailed distribution table for the forced-choice democracy item
cat("\n=== dem_essential_harmonized: Response distributions by period ===\n")

essential_labels <- c(
  "1" = "Electoral (free/fair elections)",
  "2" = "Expressive (freedom to express)",
  "3" = "Redistributive (narrow gap)",
  "4" = "Basic needs (necessities for all)",
  "5" = "Good governance (no waste)"
)

essential_dist <- hk5_analysis |>
  filter(period %in% c("Protest", "Post-NSL"),
         !is.na(dem_essential_harmonized)) |>
  group_by(period) |>
  count(response = dem_essential_harmonized) |>
  mutate(
    pct = n / sum(n) * 100,
    response_label = essential_labels[as.character(response)]
  ) |>
  ungroup()

essential_wide <- essential_dist |>
  select(period, response_label, pct) |>
  pivot_wider(names_from = period, values_from = pct, values_fill = 0) |>
  mutate(
    shift = `Post-NSL` - Protest,
    response_label = factor(response_label, levels = essential_labels)
  ) |>
  arrange(response_label)

essential_wide |>
  mutate(across(c(Protest, `Post-NSL`, shift), ~round(.x, 1))) |>
  kable(
    col.names = c("Response", "% Protest", "% Post-NSL", "Shift (pp)"),
    caption = "Most essential element of democracy: response distribution by period (HK Wave 5)",
    booktabs = TRUE
  ) |>
  kable_styling(latex_options = c("hold_position"))

# Also compute for dem_always_preferable
cat("\n=== dem_always_preferable: Response distributions by period ===\n")

preferable_labels <- c(
  "1" = "Democracy always preferable",
  "2" = "Authoritarian sometimes preferable",
  "3" = "Doesn't matter"
)

preferable_dist <- hk5_analysis |>
  filter(period %in% c("Protest", "Post-NSL"),
         !is.na(dem_always_preferable)) |>
  group_by(period) |>
  count(response = dem_always_preferable) |>
  mutate(
    pct = n / sum(n) * 100,
    response_label = preferable_labels[as.character(response)]
  ) |>
  ungroup()

preferable_wide <- preferable_dist |>
  select(period, response_label, pct) |>
  pivot_wider(names_from = period, values_from = pct, values_fill = 0) |>
  mutate(
    shift = `Post-NSL` - Protest,
    response_label = factor(response_label, levels = preferable_labels)
  ) |>
  arrange(response_label)

preferable_wide |>
  mutate(across(c(Protest, `Post-NSL`, shift), ~round(.x, 1))) |>
  kable(
    col.names = c("Response", "% Protest", "% Post-NSL", "Shift (pp)"),
    caption = "Democracy always preferable: response distribution by period (HK Wave 5)",
    booktabs = TRUE
  ) |>
  kable_styling(latex_options = c("hold_position"))
```


# ============================================================
# SAVE ALL RESULTS
# ============================================================

```{r save-results}
# Collect results into a list, handling objects that may not exist
results_to_save <- list(
  ols_results = ols_results,
  sensitivity_results = sensitivity_results,
  fdr_results = fdr_results,
  var_labels = var_labels,
  primary_outcomes = primary_outcomes,
  primary_labels = primary_labels,
  covariates = covariates
)

if (exists("combined_table")) results_to_save$combined_table <- combined_table
if (exists("reweighted_results")) results_to_save$reweighted_results <- reweighted_results
if (exists("falsification_results")) results_to_save$falsification_results <- falsification_results
if (exists("nr_comparison")) results_to_save$nr_comparison <- nr_comparison
if (exists("dem_summary_table")) results_to_save$dem_summary_table <- dem_summary_table
if (exists("dem_effects")) results_to_save$dem_effects <- dem_effects
if (exists("dem_missing")) results_to_save$dem_missing <- dem_missing
if (exists("dem_distributions")) results_to_save$dem_distributions <- dem_distributions
if (exists("essential_wide")) results_to_save$essential_wide <- essential_wide
if (exists("preferable_wide")) results_to_save$preferable_wide <- preferable_wide

# Save individual objects to the environment for easy loading
for (nm in names(results_to_save)) {
  assign(nm, results_to_save[[nm]])
}

do.call(save, c(lapply(names(results_to_save), as.name),
               list(file = "results/main_analysis_results.RData")))

cat("\nResults saved to results/main_analysis_results.RData\n")
```
