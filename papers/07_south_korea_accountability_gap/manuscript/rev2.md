Revision Prose: Alternative Explanations & Measurement Transparency
Instructions for CC
This document contains two new prose sections and one set of targeted edits. Block 7 is a new subsection for the Discussion addressing alternative explanations (Reviewer Concern D). Block 8 is new prose for the Methods section making measurement comparability explicit (Reviewer Concern A). Block 9 tightens causal language throughout.
***BLOCK 7: New Discussion Subsection — Alternative Explanations
Target: Insert after the current paragraph on cross-partisan erosion (page 30, ending "...since it cannot be addressed simply by changing the government.") and before the reputational reconstitution paragraph. This should be a new subsection header: 6.1 Alternative Explanations (or unnumbered, depending on AISR formatting — AISR uses only two heading levels, bold for first and bold italic for second).
Insert:
Several alternative accounts of the intermediary trust collapse deserve direct engagement, since the theoretical claim — that the pattern reflects a structural feature of the accountability environment rather than a confound — depends on their inadequacy.
The most immediate alternative is government popularity. The 2016 KAMOS wave was fielded under the Park administration, already engulfed in scandal; the 2019 wave under Moon Jae-in, who entered office with approval ratings above seventy percent. If the trust decline reflects nothing more than the contrast between a disgraced conservative incumbent and a popular progressive successor, one would expect trust in central government to rise between waves — Moon's supporters replacing Park's in the sample should push executive trust upward. It did not. Central government trust fell, modestly, from 4.85 to 4.73. The Moon administration's popularity did not translate into institutional trust recovery even for the institutions most directly associated with the sitting government. The intermediary collapse, meanwhile, occurred under a president whose own party controlled the National Assembly — a configuration that should, under a popularity account, have buffered legislative trust rather than allowing it to fall by 0.60 points. The pattern cuts against a straightforward incumbent-evaluation explanation.
A second alternative concerns mode effects. The KAMOS is a multimode survey, and trust items are known to be sensitive to administration mode — face-to-face interviewing tends to produce higher trust scores than web-based or telephone modes, partly through social desirability. If the 2019 wave shifted toward less personal modes relative to 2016, the trust decline could partly reflect methodological artifact. This possibility cannot be definitively excluded with the information available in the public-use data. Two features of the results, however, sit uneasily with a pure mode-effects account. First, the decline is strikingly differentiated: central government trust barely moved while civil society trust fell by 0.71 points. Mode effects would be expected to depress trust scores roughly uniformly across institutions, since the social desirability pressure to report trust operates at the level of the survey interaction, not at the level of specific institutional referents. Second, the ABS — administered exclusively face-to-face across all Korean waves — shows a parallel pattern of rising transparency concerns and declining experiential corruption across the same interval. The convergence of two independent instruments with different mode profiles strengthens the case that the KAMOS trust decline reflects substantive perceptual change rather than mode-driven measurement error.
Third, issue-specific shocks unrelated to accountability could explain the intermediary decline. Korean media faced a credibility crisis in this period that extended well beyond the impeachment narrative — the proliferation of partisan online outlets, the erosion of broadcast journalism's gatekeeper role, and several high-profile fabrication scandals all contributed to media distrust independently of any accountability dynamic. Civil society organizations confronted their own legitimacy challenges, including questions about NGO governance, funding transparency, and perceived partisan capture. These institution-specific pressures are real and almost certainly contributed to the magnitude of the observed trust declines. The question is whether they can account for the pattern — the structured divergence between executive stability and intermediary collapse. An institution-specific shock account predicts that each intermediary's decline should track its own scandal history, producing heterogeneous magnitudes and idiosyncratic timing. What the data show instead is a coherent bloc decline: all four intermediary institutions fell by between 0.60 and 0.71 points, a range narrow enough to suggest a common underlying driver operating across institutionally distinct referents. The accountability gap interpretation does not require that institution-specific pressures played no role — only that they are insufficient to explain the structured pattern without reference to the broader accountability shock that affected the entire intermediary ecosystem simultaneously.
Finally, polarization mechanisms may confound the cross-partisan claim. Near-zero correlations between ideology and trust at each wave do not rule out the possibility that changes in trust were ideologically structured — that conservative respondents lost trust in media they perceived as hostile to Park while progressive respondents lost trust in institutions they perceived as complicit in enabling her. The net effect could produce near-zero cross-sectional correlations at each timepoint while masking heterogeneous partisan dynamics underneath. The controlled model's inclusion of ideology and party identification as covariates partially addresses this concern — the Wave × InstitutionType interaction terms remain large and significant after these controls — but the absence of panel data prevents direct observation of within-person partisan dynamics. This is a genuine limitation. Future research with panel data covering the impeachment period could adjudicate between the structural and partisan-heterogeneity interpretations more directly.
***BLOCK 8: New Methods Prose — Measurement Transparency for corrupt_witnessed
Target: Insert after the current paragraph on corrupt_witnessed operationalization in Section 4 (page 12–13, after "...higher values indicating greater frequency"). This replaces the current brief mention with an explicit treatment of the comparability issue, as the reviewer demanded.
Insert:
A measurement caveat is essential here. The corrupt_witnessed item was not administered with identical wording across all six ABS waves. The core question — whether the respondent or a family member has encountered a government official who demanded corrupt payment — is consistent across the series, but the response architecture varied. Waves 1, 2, 5, and 6 used a binary format (yes/no). Wave 3 included an additional response option ("No one I know has personally witnessed") that was collapsed to the "no" category for harmonization. Wave 4 used a five-category scale distinguishing personal, second-hand, and third-hand witnessing, with categories 1–3 collapsed to 1 and 4–5 to 0. These recoding decisions are documented in Appendix A and the harmonization pipeline.
The practical consequence is that wave-to-wave comparisons in the experiential series rest on the assumption that the collapsed binary categories capture approximately the same construct across waves — an assumption that is defensible but not guaranteed. The W4→W5 interval, which spans the accountability shock and registers the largest single-wave decline (0.162 to 0.021), is the most consequential comparison for the theoretical argument, and it involves a transition from the five-category W4 instrument back to a binary W5 format. Two considerations mitigate concern that this transition drives the observed decline. First, the alternative coding of the W4 item — restricting the "yes" category to personal experience only, excluding second-hand and third-hand witnessing — produces a W4 mean of [CC: INSERT VALUE FROM SENSITIVITY ANALYSIS] rather than 0.162, and the W4→W5 decline under this specification is [CC: INSERT VALUE], substantively similar to the baseline coding. Second, the direction of the W3→W4 comparison — where the instrument changed from the three-option W3 format to the five-category W4 format — shows a comparatively modest decline of 0.018 points, suggesting that format changes alone do not mechanically produce large shifts in the series. The sharp W4→W5 decline is concentrated in the interval where the Kim Young-ran Act and the impeachment occurred, not in the intervals where the instrument format changed.
Nevertheless, the analysis does not rest on the experiential series alone. The divergence between the experiential and institutional corruption series — rather than the absolute level or trajectory of either series in isolation — is the theoretically relevant test. Both institutional series use a consistent four-point response format across all six waves, and neither shows a trend or a discontinuity in the accountability shock interval. The divergence test reported in Appendix B places both series on a common 0–1 scale and formally contrasts their W4→W5 changes, finding a statistically significant difference (estimate = −0.119, SE = 0.017, z = −6.96, p < .001). This test is robust to the measurement concerns described above because it asks whether the two series moved differently across the critical interval, not whether either series attained a particular absolute value.
***BLOCK 9: Causal Language Tightening — Global Replacements
Instructions for CC: These are targeted find-and-replace operations across the full .qmd. In each case, the replacement softens the causal claim to be appropriate for repeated cross-sectional data.
| Find (approximate context) | Replace with |
|---|---|
| "the perceptual reorganization induced by the accountability shock" (p. 16) | "the perceptual reorganization associated with the accountability shock" |
| "the accountability shock of 2016–2018 damaged not the standing of government" (p. 29) | "the accountability shock of 2016–2018 appears to have damaged not the standing of government" |
| "the accountability shock reorganized citizens' perceptions" (p. 24) | "the accountability shock was associated with a reorganization of citizens' perceptions" |
| "a backsliding episode that weakens the mechanisms of horizontal accountability should register in mass opinion as" (p. 19) | "a backsliding episode that weakens the mechanisms of horizontal accountability would be expected to register in mass opinion as" |
| "the Candlelight Revolution and the subsequent impeachment together constituted precisely such a moment" (Section 2, ~p. 5) | keep as is — this describes a historical event, not a causal claim |
| "the Act did not merely prohibit specific acts; it reorganized the conceptual landscape" (p. 5–6) | "the Act did not merely prohibit specific acts; the analysis developed here suggests it reorganized the conceptual landscape" |
| "backsliding episodes produce a distinctive mass public signature" (p. 32) | "backsliding episodes may produce a distinctive mass public signature" |
| "creating a feedback dynamic in which elite-level erosion and mass-level perceptual change reinforce one another" (p. 32) | "potentially creating a feedback dynamic in which elite-level erosion and mass-level perceptual change reinforce one another" |
General rule for CC's audit: Any sentence that uses "produced," "generated," "caused," "drove," or "induced" with the accountability shock as the subject should be evaluated. If the evidence is timing-based rather than identification-based, soften to "was associated with," "is consistent with," "aligned with the timing of," or "suggests." Exceptions: historical facts about the impeachment, the Kim Young-ran Act's enactment, and electoral outcomes are not causal claims and should retain assertive language.
***BLOCK 10: Clarifying "Backsliding" — Targeted Edit in Introduction
Target: The sentence on page 2: "the central argument is that backsliding episodes produce a distinctive mass public signature, here termed the accountability gap syndrome..."
The reviewer noted that impeachment could be read as accountability success, making the "backsliding" framing ambiguous. This needs a one-sentence clarification immediately following.
After the current sentence, insert:
The term "backsliding" as used here refers not to the institutional outcome of the accountability crisis — which, by most measures, was a democratic success — but to the broader pattern of elite-level accountability failure that precipitated it and the mass-level perceptual residue it left behind. The impeachment resolved the constitutional crisis; it did not resolve the accountability gap that the crisis revealed.
***BLOCK 11: Reputational Reconstitution — Expanded Measurement Caveat
Target: Expand the existing reputational reconstitution paragraph (page 30–31) with an explicit note about what this means for the partisan sorting analysis.
After the sentence ending "...the perceptual residue of scandal remains without a stable organizational target," add:
This rebranding dynamic also presents a measurement challenge for the partisan sorting analysis reported above. The party identification variable in KAMOS Wave 1 (2016) codes Saenuri supporters; by Wave 4 (2019), the same ideological constituency had reorganized under the Liberty Korea Party label. Whether a respondent coded as "Liberty Korea" in 2019 represents the same partisan orientation as a "Saenuri" supporter in 2016 is a question the cross-sectional design cannot answer at the individual level. The near-zero ideology-trust correlations at each wave provide some reassurance that the trust collapse is not structured along the left-right dimension that party rebranding most directly affects — but the possibility that reputational reconstitution introduced noise into the party identification measure, attenuating cross-wave partisan comparisons, cannot be excluded. Panel data tracking the same individuals through the rebranding episode would substantially clarify this issue.
***Summary of All Prose Blocks
| Block | Location | What it does |
|---|---|---|
| 1 | Section 5.1, results | Reframes corrupt_witnessed as decline, builds reclassification argument around divergence |
| 2 | Section 6, discussion | Matching discussion reframe |
| 3 | Section 2, theory | Reframes reclassification prediction to be direction-agnostic |
| 4 | Section 2, H2 | Revised hypothesis statement |
| 5 | Abstract | One-sentence fix |
| 6 | Introduction | Direction fixes |
| 7 | Section 6, discussion | New alternative explanations subsection |
| 8 | Section 4, methods | New measurement transparency prose |
| 9 | Throughout | Causal language softening |
| 10 | Introduction | Clarifying "backsliding" |
| 11 | Discussion | Reputational reconstitution measurement caveat |
Blocks 1–6 are in the first revision file. Blocks 7–11 are in this file. CC should apply blocks in numerical order to avoid conflicts.